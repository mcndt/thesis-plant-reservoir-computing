{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))  # for importing local packages from src\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))  # for importing model config\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath} \\usepackage{gensymb} \\usepackage{siunitx}'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.rc_dataset import ExperimentDataset\n",
    "\n",
    "DATASET_PATH = '../datasets/hydroshoot_large_trimmed.csv'\n",
    "\n",
    "dataset = ExperimentDataset(csv_path=DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from src.learning.scorers import nmse_scorer\n",
    "from pipeline_hydroshoot import GroupGenerator, TimeGenerator\n",
    "from pipeline_base import TrainTestSplitter, DirectTransform, WarmupTransform\n",
    "\n",
    "# constants\n",
    "DATASET_ID = 'HydroShoot_large'\n",
    "STATE_SIZE = 32\n",
    "\n",
    "\n",
    "# Reservoir generation\n",
    "np.random.seed(42)\n",
    "state_ids = np.random.choice(dataset.state_size(), size=STATE_SIZE, replace=False)\n",
    "\n",
    "\n",
    "# readout model\n",
    "readout_model = Pipeline([\n",
    "  ('ridge_regression', Ridge(alpha=1, fit_intercept=True))\n",
    "])\n",
    "model_param_grid = [{\n",
    "  'ridge_regression__alpha': 10 ** np.linspace(np.log10(1e-4), np.log10(1e2), 50)\n",
    "}]\n",
    "\n",
    "\n",
    "# Regression task pipeline\n",
    "datasets = (dataset,)\n",
    "run_ids = dataset.get_run_ids()\n",
    "shared_pipeline_params = {\n",
    "  # Data generation\n",
    "  'datasets': datasets,\n",
    "  'groups': GroupGenerator(day_length=24, run_ids=run_ids, days_between_runs=1),\n",
    "  'time': TimeGenerator(day_length=24, run_ids=run_ids),\n",
    "  \n",
    "  # Model training and validation\n",
    "  'readout_model': readout_model,\n",
    "  'model_param_grid': model_param_grid,\n",
    "  'model_scorer': nmse_scorer,\n",
    "  'folds': GroupKFold(n_splits=5),\n",
    "  'train_test_split': TrainTestSplitter(block_size=4, test_ratio=0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_base import (\n",
    "  RCPipeline, \n",
    "  Rescale, \n",
    "  DaylightMask\n",
    ")\n",
    "\n",
    "from pipeline_hydroshoot import (\n",
    "  TargetGenerator, \n",
    "  SingleReservoirGenerator,\n",
    "  MultiReservoirGenerator,\n",
    "  TargetReservoirGenerator,\n",
    "  GroupRescale\n",
    ")\n",
    "\n",
    "\n",
    "from model_config_hydroshoot import (\n",
    "  targets, \n",
    "  measurable_reservoirs,\n",
    "  baseline_reservoirs,\n",
    "  heterogeneous_reservoirs, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_Tac',\n",
       " 'input_u',\n",
       " 'input_hs',\n",
       " 'input_Rg',\n",
       " 'output_Rg',\n",
       " 'output_An',\n",
       " 'output_E',\n",
       " 'output_Tleaf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_Tac', 'input_u', 'input_hs', 'input_Rg', 'output_Rg', 'output_An', 'output_E', 'output_Tleaf']\n",
      "['state_Tlc', 'state_E', 'state_gs']\n",
      "[('env_all', ['input_Tac', 'input_u', 'input_hs', 'input_Rg']), ('env_temp', ['input_Tac']), ('env_humidity', ['input_hs']), ('env_PAR', ['input_Rg']), ('env_wind', ['input_u'])]\n",
      "[('state_all', ('state_An', 'state_Tlc', 'state_gs', 'state_E', 'state_Flux', 'state_psi_head'))]\n"
     ]
    }
   ],
   "source": [
    "measurable_reservoirs = ['state_Tlc', 'state_E', 'state_gs']\n",
    "final_targets = ['input_Rg', 'output_Rg', 'output_An']\n",
    "narma_targets = ['input_Rg']\n",
    "\n",
    "target_state_pairs = [(target, state_var) for target in final_targets for state_var in measurable_reservoirs]\n",
    "narma_pairs = [(target, state_var) for target in narma_targets for state_var in measurable_reservoirs]\n",
    "target_env_pairs = []\n",
    "target_het_pairs = []\n",
    "\n",
    "print(targets)\n",
    "print(measurable_reservoirs)\n",
    "print(baseline_reservoirs)\n",
    "print(heterogeneous_reservoirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_base import NarmaTargetTransform\n",
    "\n",
    "input_phys_transforms = [\n",
    "  WarmupTransform(warmup_days=4, day_length=24),\n",
    "  DirectTransform()\n",
    "]\n",
    "\n",
    "\n",
    "def generate_single(target_state_pairs, state_ids):\n",
    "  for target, state_var in target_state_pairs:\n",
    "    pipeline = RCPipeline(\n",
    "      metadata={'target_id': target, 'reservoir_id': state_var, 'dataset_id': DATASET_ID},\n",
    "      # Data generation\n",
    "      target=TargetGenerator(target=target, run_ids=run_ids),\n",
    "      reservoir=SingleReservoirGenerator(state_var=state_var, run_ids=run_ids, state_ids=state_ids),\n",
    "      # Data transformation\n",
    "      transforms=input_phys_transforms,\n",
    "      # Data preprocessing\n",
    "      preprocessing=[\n",
    "        DaylightMask(day_length=24, start=5, end=21),\n",
    "        Rescale(per_feature=False)\n",
    "      ],\n",
    "      **shared_pipeline_params,\n",
    "    )\n",
    "    yield pipeline\n",
    "\n",
    "\n",
    "def generate_multi(target_het_pairs, state_ids):\n",
    "  for name, target, state_vars in target_het_pairs:\n",
    "    pipeline = RCPipeline(\n",
    "      metadata={'target_id': target, 'reservoir_id': name, 'dataset_id': DATASET_ID},\n",
    "      # Data generation\n",
    "      target=TargetGenerator(target=target, run_ids=run_ids),\n",
    "      reservoir=MultiReservoirGenerator(state_vars=state_vars, run_ids=run_ids, state_ids=state_ids),\n",
    "      # Data transformation\n",
    "      transforms=input_phys_transforms,\n",
    "      # Data preprocessing\n",
    "      preprocessing=[\n",
    "        DaylightMask(day_length=24, start=5, end=21),\n",
    "        GroupRescale(datasets=datasets, state_vars=state_vars, state_ids=state_ids)\n",
    "      ],\n",
    "      **shared_pipeline_params,\n",
    "    )\n",
    "    yield pipeline\n",
    "\n",
    "\n",
    "def generate_env(target_env_pairs):\n",
    "  for name, target, env_targets in target_env_pairs:\n",
    "    pipeline = RCPipeline(\n",
    "      metadata={'target_id': target, 'reservoir_id': name, 'dataset_id': DATASET_ID},\n",
    "      # Data generation\n",
    "      target=TargetGenerator(target=target, run_ids=run_ids),\n",
    "      reservoir=TargetReservoirGenerator(targets=env_targets, run_ids=run_ids),\n",
    "      # Data transformation\n",
    "      transforms=input_phys_transforms,\n",
    "      # Data preprocessing\n",
    "      preprocessing=[\n",
    "        DaylightMask(day_length=24, start=5, end=21),\n",
    "        Rescale(per_feature=True)\n",
    "      ],\n",
    "      **shared_pipeline_params,\n",
    "    )\n",
    "    yield pipeline\n",
    "\n",
    "def narma_benchmark(target_state_pairs, state_ids, *, n):\n",
    "  for target, state_var in target_state_pairs:\n",
    "    pipeline = RCPipeline(\n",
    "      metadata={\n",
    "        'target_id': f'{target}_NARMA_{n}', \n",
    "        'reservoir_id': state_var, \n",
    "        'dataset_id': DATASET_ID,\n",
    "        'benchmark': 'NARMA',\n",
    "        'narma_n': n,\n",
    "      },\n",
    "      # Data generation\n",
    "      target=TargetGenerator(target=target, run_ids=run_ids),\n",
    "      reservoir=SingleReservoirGenerator(state_var=state_var, run_ids=run_ids, state_ids=state_ids),\n",
    "      # Data transformation\n",
    "      transforms=[\n",
    "        # NOTE: remove warmup before transform, otherwise the \n",
    "        # warmup steps are used as input to the NARMA system.\n",
    "        WarmupTransform(warmup_days=4, day_length=24),  \n",
    "        NarmaTargetTransform(n=n, scale=1),\n",
    "      ],\n",
    "      # Data preprocessing\n",
    "      preprocessing=[\n",
    "        DaylightMask(day_length=24, start=5, end=21),\n",
    "        Rescale(per_feature=False)\n",
    "      ],\n",
    "      **shared_pipeline_params,\n",
    "    )\n",
    "    yield pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pipelines: 12\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def generate_pipelines(state_ids):\n",
    "  pipelines = list(chain(\n",
    "    generate_single(target_state_pairs, state_ids),\n",
    "    generate_multi(target_het_pairs, state_ids),\n",
    "    generate_env(target_env_pairs),\n",
    "    narma_benchmark(narma_pairs, state_ids, n=8)\n",
    "  ))\n",
    "  return pipelines\n",
    "\n",
    "\n",
    "pipelines = generate_pipelines(state_ids)\n",
    "print(f'Total pipelines: {len(pipelines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from pipeline_base import execute_pipeline\n",
    "\n",
    "\n",
    "\n",
    "total_loops = len(pipelines)\n",
    "results = []\n",
    "model_data = []\n",
    "\n",
    "with tqdm(total=total_loops) as pbar:\n",
    "  for pipeline in pipelines:\n",
    "\n",
    "    try:\n",
    "      result, md = execute_pipeline(pipeline, return_model_data=True)\n",
    "      results.append(result)\n",
    "      model_data.append(md)\n",
    "      pbar.update(1)\n",
    "    except Exception as e:\n",
    "      print('An exception occured executing the pipeline with the following metadata:')\n",
    "      print(f'{pipeline.metadata}')\n",
    "      raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_Rg__true',\n",
       " 'input_Rg__state_Tlc',\n",
       " 'input_Rg__state_E',\n",
       " 'input_Rg__state_gs',\n",
       " 'output_Rg__true',\n",
       " 'output_Rg__state_Tlc',\n",
       " 'output_Rg__state_E',\n",
       " 'output_Rg__state_gs',\n",
       " 'output_An__true',\n",
       " 'output_An__state_Tlc',\n",
       " 'output_An__state_E',\n",
       " 'output_An__state_gs',\n",
       " 'input_Rg_NARMA_8__true',\n",
       " 'input_Rg_NARMA_8__state_Tlc',\n",
       " 'input_Rg_NARMA_8__state_E',\n",
       " 'input_Rg_NARMA_8__state_gs']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydroshoot_pred = {}\n",
    "\n",
    "\n",
    "for result, md in zip(results, model_data):\n",
    "  model = md['final_model']\n",
    "  X_test, y_test = md['test_data']\n",
    "  target_id = result['target_id']\n",
    "  reservoir_id = result['reservoir_id']\n",
    "  y_pred = model.predict(X_test)\n",
    "  hydroshoot_pred[f'{target_id}__true'] = y_test\n",
    "  hydroshoot_pred[f'{target_id}__{reservoir_id}'] = y_pred\n",
    "\n",
    "\n",
    "list(hydroshoot_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_pred_fixed = {}\n",
    "\n",
    "for name, pred in hydroshoot_pred.items():\n",
    "  l = len(pred)\n",
    "  new_pred = np.ones(1968) * np.NaN\n",
    "  new_pred[:l] = pred\n",
    "  hs_pred_fixed[name] = new_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1968, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(hs_pred_fixed)\n",
    "pred_df.to_csv('results_hydroshoot_input_phys_predictions.csv')\n",
    "\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4121734fd62df77af0346899b5494e4291ab6203437ffd47de4eeaba662aa73c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rc-plants')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
