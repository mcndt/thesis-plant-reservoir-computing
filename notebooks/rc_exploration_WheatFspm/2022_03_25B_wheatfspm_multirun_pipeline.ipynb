{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multirun experiment pipeline (WheatFspm)\n",
    "\n",
    "The following notebook establishes a generalized pipeline for evaluating a computing reservoir against a given task, given multiple experimental runs of the same reservoir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))  # for importing local packages from src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NEMA_H0 = '../datasets/dataset_NEMA_NEMA_H0.csv'\n",
    "DATASET_NEMA_H3 = '../datasets/dataset_NEMA_NEMA_H3.csv'\n",
    "DATASET_NEMA_H15 = '../datasets/dataset_NEMA_NEMA_H15.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets\n",
    "\n",
    "These datasets were collected and converted in the WheatFspm repository.\n",
    "\n",
    "There are three simulations made available in the WheatFspm repository that are useable for RC experiments: NEMA H0, H3 and H15.\n",
    "\n",
    "We can try using these datasets in two different ways:\n",
    "\n",
    "1. Treat every dataset as a separate plant, training a readout for each simulation run.\n",
    "2. Concatenating the three datasets as observed behavior of a single plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.rc_dataset import ExperimentDataset\n",
    "\n",
    "dataset_nema_h0 = ExperimentDataset(csv_path=DATASET_NEMA_H0)\n",
    "dataset_nema_h3 = ExperimentDataset(csv_path=DATASET_NEMA_H3)\n",
    "dataset_nema_h15 = ExperimentDataset(csv_path=DATASET_NEMA_H15)\n",
    "\n",
    "datasets = [\n",
    "  ('NEMA_H0', dataset_nema_h0), \n",
    "  ('NEMA_H3', dataset_nema_h3), \n",
    "  ('NEMA_H15', dataset_nema_h15)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining targets and observed state variables\n",
    "\n",
    "These were selected in a previous notebook, `2022_03_23_wheatfspm_dataset_inspection.ipynb` and are defined in a config file for reuse among notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "\t- input_air_temperature\n",
      "\t- input_humidity\n",
      "\t- input_Wind\n",
      "\t- input_PARi\n",
      "\t- output__axes__Total_Transpiration\n",
      "\t- output__axes__C_exudated\n",
      "\t- output__axes__SAM_temperature\n",
      "\t- output__axes__delta_teq\n",
      "\t- output__axes__sum_respi_shoot\n",
      "\t- output__organ_roots__N_exudation\n",
      "\n",
      "State variables:\n",
      "\t- state__An\n",
      "\t- state__Transpiration\n",
      "\t- state__S_Sucrose\n",
      "\t- state__Ts\n",
      "\t- state__gs\n",
      "\t- state__Ag\n",
      "\t- state__Tr\n",
      "\t- state__sucrose\n",
      "\t- state__Rd\n",
      "\t- state__sum_respi\n",
      "\t- state__Photosynthesis\n",
      "\t- state__PARa\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "from model_config import targets, state_variables\n",
    "\n",
    "print(f'Targets:')\n",
    "for target in targets:\n",
    "  print(f'\\t- {target}')\n",
    "\n",
    "print(f'\\nState variables:')\n",
    "for state_var in state_variables:\n",
    "  print(f'\\t- {state_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing, grouping and train-test splitting\n",
    "\n",
    "The available datasets will be processed into 4 datasets:\n",
    "\n",
    "- NEMA_H0\n",
    "- NEMA_H3\n",
    "- NEMA_H15\n",
    "- NEMA_COMBINED (concatenated as data from the same plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.learning.preprocessing import generate_mask\n",
    "\n",
    "\n",
    "WARMUP_STEPS = 4 * 24\n",
    "DAY_MASK = generate_mask(5, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wheatfspm_pipeline_utils import preprocess_data, group_by_day, train_test_split_alternating\n",
    "from wheatfspm_pipeline_utils import direct_target_generator, direct_reservoir_generator\n",
    "from wheatfspm_pipeline_utils import preprocess_raw_X\n",
    "from model_config import max_time_step\n",
    "\n",
    "def generate_X_y_groups(datasets, target_generator, state_generator):\n",
    "  \"\"\"Generates X, y and groups arrays for each dataset, plus a concatenated dataset.\n",
    "     NOTE: The groups in the concatenated dataset are such that the same calendar day is in the same group.\n",
    "\n",
    "     Also generates a baseline dataset where the reservoir is just a combination of all environmental inputs.\n",
    "  \"\"\"\n",
    "  data = {}\n",
    "\n",
    "  # Preprocess the data for each dataset\n",
    "  for name, dataset in datasets:\n",
    "    target_data = next(target_generator(dataset, target, name))\n",
    "    reservoir_data = next(state_generator(dataset, state_var, name))\n",
    "    X_raw, y_raw = preprocess_data(dataset, target_data, reservoir_data, WARMUP_STEPS, DAY_MASK)\n",
    "    X, y = X_raw[0, :, :], y_raw[0, :]\n",
    "    groups = group_by_day(X, DAY_MASK)\n",
    "    data[name] = (X, y, groups)\n",
    "\n",
    "  # Generate the concatenated dataset\n",
    "  all_arrays = list(data.values())\n",
    "  X_combined = np.concatenate(list(map(lambda x : x[0], all_arrays)))\n",
    "  y_combined = np.concatenate(list(map(lambda x : x[1], all_arrays)))\n",
    "  groups_combined = np.concatenate(list(map(lambda x : x[2], all_arrays)))\n",
    "  data['combined'] = (X_combined, y_combined, groups_combined)\n",
    "\n",
    "  # Generate the baseline dataset\n",
    "  baseline_name, baseline_dataset = datasets[0]\n",
    "  input_vars = baseline_dataset.get_input_variables()\n",
    "  X_baseline = np.empty((max_time_step[baseline_name], len(input_vars)))\n",
    "  for i, var in enumerate(input_vars):\n",
    "    X_baseline[:, i] = baseline_dataset.get_target(var, baseline_name)[:max_time_step[baseline_name]]\n",
    "  X_baseline = preprocess_raw_X(X_baseline, WARMUP_STEPS, DAY_MASK)\n",
    "  y_baseline = data[baseline_name][1]\n",
    "  groups_baseline = data[baseline_name][2]\n",
    "  data[f'baseline_{baseline_name}'] = X_baseline, y_baseline, groups_baseline\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEMA_H0:\n",
      "\tX: (400, 13)\n",
      "\ty: (400,)\n",
      "\tgroups: 25 (shape (400,))\n",
      "NEMA_H3:\n",
      "\tX: (512, 13)\n",
      "\ty: (512,)\n",
      "\tgroups: 32 (shape (512,))\n",
      "NEMA_H15:\n",
      "\tX: (544, 13)\n",
      "\ty: (544,)\n",
      "\tgroups: 34 (shape (544,))\n",
      "combined:\n",
      "\tX: (1456, 13)\n",
      "\ty: (1456,)\n",
      "\tgroups: 34 (shape (1456,))\n",
      "baseline_NEMA_H0:\n",
      "\tX: (400, 4)\n",
      "\ty: (400,)\n",
      "\tgroups: 25 (shape (400,))\n"
     ]
    }
   ],
   "source": [
    "TARGET = targets[0]\n",
    "STATE_VAR = state_variables[0]\n",
    "\n",
    "preprocessed_data = generate_X_y_groups(datasets, direct_target_generator, direct_reservoir_generator)\n",
    "\n",
    "for name, (X, y, groups) in preprocessed_data.items():\n",
    "  print(f'{name}:')\n",
    "  print(f'\\tX: {X.shape}')\n",
    "  print(f'\\ty: {y.shape}')\n",
    "  print(f'\\tgroups: {len(np.unique(groups))} (shape {groups.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "- Readout model is a standard RidgeRegression model with intercept term and CV-tuned regularization strength $\\alpha$.\n",
    "- CV search grid is a progression of logarithmicly spaced values for regularization strength $\\alpha$.\n",
    "- CV and testing metric is NMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from src.learning.scorers import nmse_scorer\n",
    "\n",
    "# Define model\n",
    "readout = Pipeline([\n",
    "  ('ridge_regression', Ridge(alpha=1, fit_intercept=True))\n",
    "])\n",
    "\n",
    "# define search grid\n",
    "search_grid = [{\n",
    "  'ridge_regression__alpha': 10 ** np.linspace(np.log10(1e-4), np.log10(1e2), 50)\n",
    "}]\n",
    "\n",
    "# define cross-validation and testing metric\n",
    "scorer = nmse_scorer\n",
    "\n",
    "# Define CV fold strategy\n",
    "folds = GroupKFold(n_splits=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a manifest of all experiments to run\n",
    "\n",
    "Currently we are only benchmarking direct target prediction, but in the future there will be other tasks generated from the base targets as well. These will be generated in this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [(target_name, direct_target_generator) for target_name in targets]\n",
    "STATE_VARS = [(state_var, direct_reservoir_generator) for state_var in state_variables]\n",
    "\n",
    "TRAIN_TEST_RATIO = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting all readout functions\n",
    "\n",
    "Process:\n",
    "\n",
    "- For each target:\n",
    "  - For each observed state variable:\n",
    "    - For each dataset:\n",
    "      1. Preprocess the data\n",
    "      2. Fit for each dataset\n",
    "      3. Store the resulting training, cross-validation and test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 600 fits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:02<00:00,  9.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.learning.training import perform_gridsearch\n",
    "\n",
    "\n",
    "total_loops = len(targets) * len(state_variables) * (len(datasets) + 2)\n",
    "print(f'Performing {total_loops} fits...')\n",
    "\n",
    "\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "\n",
    "with tqdm(total=total_loops) as pbar:\n",
    "\n",
    "    for target_name, target_generator in TARGETS:\n",
    "        for state_var, state_generator in STATE_VARS:\n",
    "\n",
    "            # Preprocess data for model fit\n",
    "            preprocessed_data = generate_X_y_groups(datasets, target_generator, state_generator)\n",
    "\n",
    "            # For each dataset combination\n",
    "            for dataset_name, (X, y, groups) in preprocessed_data.items():\n",
    "                train, test = train_test_split_alternating(X, y, groups, ratio=TRAIN_TEST_RATIO)\n",
    "\n",
    "                # fit model\n",
    "                X_train, y_train, groups_train = train\n",
    "                model, scores = perform_gridsearch(readout, X_train, y_train, groups_train, folds, search_grid, verbose=False)\n",
    "                (train_mean, train_std), (cv_mean, cv_std) = scores\n",
    "\n",
    "                # Determine test score\n",
    "                X_test, y_test, _ = test\n",
    "                test_score = scorer(model, X_test, y_test)\n",
    "\n",
    "                # store results\n",
    "                models[(target_name, state_var, dataset_name)] = model\n",
    "                results.append({\n",
    "                    'target': target_name,\n",
    "                    'state_var': state_var,\n",
    "                    'dataset': dataset_name,\n",
    "                    'test_score': test_score,\n",
    "                    'train_mean': train_mean,\n",
    "                    'train_std': train_std,\n",
    "                    'cv_mean': cv_mean,\n",
    "                    'cv_std': cv_std\n",
    "                })\n",
    "\n",
    "                pbar.update(1)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing experiment results\n",
    "\n",
    "Storing all the fit results into a Pandas dataframe, then storing it as a CSV file for further inspection in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>state_var</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>cv_mean</th>\n",
       "      <th>cv_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__An</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.299655</td>\n",
       "      <td>-0.235367</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>-0.413253</td>\n",
       "      <td>0.094021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__An</td>\n",
       "      <td>NEMA_H3</td>\n",
       "      <td>-1.070000</td>\n",
       "      <td>-0.266628</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>-0.576058</td>\n",
       "      <td>0.321516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__An</td>\n",
       "      <td>NEMA_H15</td>\n",
       "      <td>-0.842455</td>\n",
       "      <td>-0.824210</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>-0.926458</td>\n",
       "      <td>0.061315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__An</td>\n",
       "      <td>combined</td>\n",
       "      <td>-0.721588</td>\n",
       "      <td>-0.671309</td>\n",
       "      <td>0.046691</td>\n",
       "      <td>-1.099954</td>\n",
       "      <td>0.447542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__An</td>\n",
       "      <td>baseline_NEMA_H0</td>\n",
       "      <td>-0.981863</td>\n",
       "      <td>-0.949312</td>\n",
       "      <td>0.038248</td>\n",
       "      <td>-1.005481</td>\n",
       "      <td>0.047781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__Transpiration</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.526377</td>\n",
       "      <td>-0.263443</td>\n",
       "      <td>0.017583</td>\n",
       "      <td>-0.415047</td>\n",
       "      <td>0.028102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__Transpiration</td>\n",
       "      <td>NEMA_H3</td>\n",
       "      <td>-0.417018</td>\n",
       "      <td>-0.522495</td>\n",
       "      <td>0.080975</td>\n",
       "      <td>-0.607136</td>\n",
       "      <td>0.174430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__Transpiration</td>\n",
       "      <td>NEMA_H15</td>\n",
       "      <td>-0.667238</td>\n",
       "      <td>-0.768667</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>-0.895744</td>\n",
       "      <td>0.096541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__Transpiration</td>\n",
       "      <td>combined</td>\n",
       "      <td>-0.555789</td>\n",
       "      <td>-0.542357</td>\n",
       "      <td>0.062261</td>\n",
       "      <td>-1.151606</td>\n",
       "      <td>0.632378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__Transpiration</td>\n",
       "      <td>baseline_NEMA_H0</td>\n",
       "      <td>-0.981863</td>\n",
       "      <td>-0.949312</td>\n",
       "      <td>0.038248</td>\n",
       "      <td>-1.005481</td>\n",
       "      <td>0.047781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  target             state_var           dataset  test_score  \\\n",
       "0  input_air_temperature             state__An           NEMA_H0   -0.299655   \n",
       "1  input_air_temperature             state__An           NEMA_H3   -1.070000   \n",
       "2  input_air_temperature             state__An          NEMA_H15   -0.842455   \n",
       "3  input_air_temperature             state__An          combined   -0.721588   \n",
       "4  input_air_temperature             state__An  baseline_NEMA_H0   -0.981863   \n",
       "5  input_air_temperature  state__Transpiration           NEMA_H0   -0.526377   \n",
       "6  input_air_temperature  state__Transpiration           NEMA_H3   -0.417018   \n",
       "7  input_air_temperature  state__Transpiration          NEMA_H15   -0.667238   \n",
       "8  input_air_temperature  state__Transpiration          combined   -0.555789   \n",
       "9  input_air_temperature  state__Transpiration  baseline_NEMA_H0   -0.981863   \n",
       "\n",
       "   train_mean  train_std   cv_mean    cv_std  \n",
       "0   -0.235367   0.036014 -0.413253  0.094021  \n",
       "1   -0.266628   0.016394 -0.576058  0.321516  \n",
       "2   -0.824210   0.017468 -0.926458  0.061315  \n",
       "3   -0.671309   0.046691 -1.099954  0.447542  \n",
       "4   -0.949312   0.038248 -1.005481  0.047781  \n",
       "5   -0.263443   0.017583 -0.415047  0.028102  \n",
       "6   -0.522495   0.080975 -0.607136  0.174430  \n",
       "7   -0.768667   0.070744 -0.895744  0.096541  \n",
       "8   -0.542357   0.062261 -1.151606  0.632378  \n",
       "9   -0.949312   0.038248 -1.005481  0.047781  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results)\n",
    "results_df.set_index(['target', 'state_var', 'dataset'])\n",
    "results_df.to_csv(f'test_results.csv')\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>state_var</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>cv_mean</th>\n",
       "      <th>cv_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>output__axes__C_exudated</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>input_Wind</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>output__axes__SAM_temperature</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>output__axes__Total_Transpiration</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>output__axes__delta_teq</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>input_PARi</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>output__axes__sum_respi_shoot</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>input_air_temperature</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>input_humidity</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>output__organ_roots__N_exudation</td>\n",
       "      <td>state__sum_respi</td>\n",
       "      <td>NEMA_H0</td>\n",
       "      <td>-0.162659</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>-0.221011</td>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target         state_var  dataset  test_score  \\\n",
       "345           output__axes__C_exudated  state__sum_respi  NEMA_H0   -0.162659   \n",
       "165                         input_Wind  state__sum_respi  NEMA_H0   -0.162659   \n",
       "405      output__axes__SAM_temperature  state__sum_respi  NEMA_H0   -0.162659   \n",
       "285  output__axes__Total_Transpiration  state__sum_respi  NEMA_H0   -0.162659   \n",
       "465            output__axes__delta_teq  state__sum_respi  NEMA_H0   -0.162659   \n",
       "225                         input_PARi  state__sum_respi  NEMA_H0   -0.162659   \n",
       "525      output__axes__sum_respi_shoot  state__sum_respi  NEMA_H0   -0.162659   \n",
       "45               input_air_temperature  state__sum_respi  NEMA_H0   -0.162659   \n",
       "105                     input_humidity  state__sum_respi  NEMA_H0   -0.162659   \n",
       "585   output__organ_roots__N_exudation  state__sum_respi  NEMA_H0   -0.162659   \n",
       "\n",
       "     train_mean  train_std   cv_mean    cv_std  \n",
       "345   -0.068266    0.00494 -0.221011  0.078401  \n",
       "165   -0.068266    0.00494 -0.221011  0.078401  \n",
       "405   -0.068266    0.00494 -0.221011  0.078401  \n",
       "285   -0.068266    0.00494 -0.221011  0.078401  \n",
       "465   -0.068266    0.00494 -0.221011  0.078401  \n",
       "225   -0.068266    0.00494 -0.221011  0.078401  \n",
       "525   -0.068266    0.00494 -0.221011  0.078401  \n",
       "45    -0.068266    0.00494 -0.221011  0.078401  \n",
       "105   -0.068266    0.00494 -0.221011  0.078401  \n",
       "585   -0.068266    0.00494 -0.221011  0.078401  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sorted = results_df.sort_values('test_score', ascending=False)\n",
    "results_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_var</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>cv_mean</th>\n",
       "      <th>cv_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_PARi</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_Wind</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_air_temperature</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_humidity</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__axes__C_exudated</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__axes__SAM_temperature</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__axes__Total_Transpiration</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__axes__delta_teq</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__axes__sum_respi_shoot</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output__organ_roots__N_exudation</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   state_var  dataset  test_score  train_mean  \\\n",
       "target                                                                          \n",
       "input_PARi                                18       18          18          18   \n",
       "input_Wind                                18       18          18          18   \n",
       "input_air_temperature                     18       18          18          18   \n",
       "input_humidity                            18       18          18          18   \n",
       "output__axes__C_exudated                  18       18          18          18   \n",
       "output__axes__SAM_temperature             18       18          18          18   \n",
       "output__axes__Total_Transpiration         18       18          18          18   \n",
       "output__axes__delta_teq                   18       18          18          18   \n",
       "output__axes__sum_respi_shoot             18       18          18          18   \n",
       "output__organ_roots__N_exudation          18       18          18          18   \n",
       "\n",
       "                                   train_std  cv_mean  cv_std  \n",
       "target                                                         \n",
       "input_PARi                                18       18      18  \n",
       "input_Wind                                18       18      18  \n",
       "input_air_temperature                     18       18      18  \n",
       "input_humidity                            18       18      18  \n",
       "output__axes__C_exudated                  18       18      18  \n",
       "output__axes__SAM_temperature             18       18      18  \n",
       "output__axes__Total_Transpiration         18       18      18  \n",
       "output__axes__delta_teq                   18       18      18  \n",
       "output__axes__sum_respi_shoot             18       18      18  \n",
       "output__organ_roots__N_exudation          18       18      18  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sorted_top = results_sorted[results_sorted['test_score'] > -0.5]\n",
    "results_sorted_top.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4121734fd62df77af0346899b5494e4291ab6203437ffd47de4eeaba662aa73c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rc-plants')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
