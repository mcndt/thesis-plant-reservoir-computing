
@misc{npec_wur_2020,
	title = {{WUR} is working on {Digital} {Twins} for tomatoes, food and farming},
	url = {https://www.npec.nl/news/wur-is-working-on-digital-twins-for-tomatoes-food-and-farming/},
	language = {English},
	urldate = {2022-05-25},
	author = {{NPEC}},
	month = sep,
	year = {2020},
}

@article{giuliani_coordination_2013,
	title = {Coordination of {Leaf} {Photosynthesis}, {Transpiration}, and {Structural} {Traits} in {Rice} and {Wild} {Relatives} ({Genus} {Oryza})},
	volume = {162},
	issn = {0032-0889, 1532-2548},
	url = {https://academic.oup.com/plphys/article/162/3/1632-1651/6110850},
	doi = {10.1104/pp.113.217497},
	language = {en},
	number = {3},
	urldate = {2022-05-22},
	journal = {PLANT PHYSIOLOGY},
	author = {Giuliani, R. and Koteyeva, N. and Voznesenskaya, E. and Evans, M. A. and Cousins, A. B. and Edwards, G. E.},
	month = jul,
	year = {2013},
	pages = {1632--1651},
}

@article{shabala_observations_1997,
	title = {Observations of {Bifurcation} and {Chaos} in {Plant} {Physiological} {Responses} to {Light}},
	volume = {24},
	issn = {1445-4408},
	url = {http://www.publish.csiro.au/?paper=PP96075},
	doi = {10.1071/PP96075},
	abstract = {Although some theoretical predictions have been made, no experimental evidence
of chaotic behaviour in plant physiological responses has been reported. Here
we present observations of period- doubling and tripling in higher plants. For
leaf bioelectric and temperature responses of maize, tomato, and burweed
plants to rhythmical light, two different routes to chaos were found
experimentally. One was via successive period-doubling and the other via the
formation of intermittently chaotic oscillations from a subharmonic
synchronisation. Because these effects appeared in intact plants, under
conditions close to those found in nature, they may have wide significance,
including for plant phylogenesis.},
	language = {en},
	number = {1},
	urldate = {2022-05-22},
	journal = {Functional Plant Biology},
	author = {Shabala, Sergey and Delbourgo, Robert and Newman, Ian},
	year = {1997},
	pages = {91},
}

@article{de_swaef_plant_2015,
	title = {Plant sensors help to understand tipburn in lettuce},
	issn = {0567-7572, 2406-6168},
	url = {https://www.actahort.org/books/1099/1099_3.htm},
	doi = {10.17660/ActaHortic.2015.1099.3},
	number = {1099},
	urldate = {2022-05-11},
	journal = {Acta Horticulturae},
	author = {De Swaef, T. and Vermeulen, K. and Vergote, N. and Van Lommel, J. and Van Labeke, M.-C. and Bleyaert, P. and Steppe, K.},
	month = sep,
	year = {2015},
	pages = {63--70},
}

@incollection{vos_groimp_2007,
	address = {Dordrecht},
	title = {Groimp as a {Platform} for {Functional}-{Structural} {Modelling} of {Plants}},
	isbn = {978-1-4020-6032-8 978-1-4020-6034-2},
	url = {http://link.springer.com/10.1007/1-4020-6034-3_4},
	language = {en},
	urldate = {2022-05-07},
	booktitle = {Functional-{Structural} {Plant} {Modelling} in {Crop} {Production}},
	publisher = {Springer Netherlands},
	author = {Kniemeyer, O. and Buck-Sorlin, G. and Kurth, W.},
	editor = {Vos, J. and Marcelis, L.F.M. and De Visser, P.H.B and Struik, P.C. and Evers, J.B.},
	year = {2007},
	doi = {10.1007/1-4020-6034-3_4},
	pages = {43--52},
}

@article{bengio_learning_1994,
	title = {Learning long-term dependencies with gradient descent is difficult},
	volume = {5},
	issn = {1045-9227, 1941-0093},
	url = {https://ieeexplore.ieee.org/document/279181/},
	doi = {10.1109/72.279181},
	number = {2},
	urldate = {2022-05-02},
	journal = {IEEE Transactions on Neural Networks},
	author = {Bengio, Y. and Simard, P. and Frasconi, P.},
	month = mar,
	year = {1994},
	pages = {157--166},
}

@article{jaeger_echo_2002,
	title = {The “echo state” approach to analysing and training recurrent neural networks - with an {Erratum} note},
	url = {https://www.ai.rug.nl/minds/uploads/EchoStatesTechRep.pdf},
	author = {Jaeger, Herbert},
	year = {2002},
}

@article{kelley_pace_sparse_1997,
	title = {Sparse spatial autoregressions},
	volume = {33},
	issn = {01677152},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016771529600140X},
	doi = {10.1016/S0167-7152(96)00140-X},
	language = {en},
	number = {3},
	urldate = {2022-05-01},
	journal = {Statistics \& Probability Letters},
	author = {Kelley Pace, R. and Barry, Ronald},
	month = may,
	year = {1997},
	pages = {291--297},
}

@misc{noauthor_notitle_nodate,
}

@article{islam_network_2010,
	title = {Network {Edge} {Intelligence} for the {Emerging} {Next}-{Generation} {Internet}},
	volume = {2},
	issn = {1999-5903},
	url = {http://www.mdpi.com/1999-5903/2/4/603},
	doi = {10.3390/fi2040603},
	language = {en},
	number = {4},
	urldate = {2022-04-24},
	journal = {Future Internet},
	author = {Islam, Salekul and Grégoire, Jean-Charles},
	month = nov,
	year = {2010},
	pages = {603--623},
}

@article{rahmani_complete_2018,
	title = {A {Complete} {Model} for {Modular} {Simulation} of {Data} {Centre} {Power} {Load}},
	url = {http://arxiv.org/abs/1804.00703},
	abstract = {Data centres are very fast growing structures with significant contribution to the world's energy consumption. Reducing the energy consumption of data centres is easier when the components that comprise a data centre and their respective energy consumption are known. A complete model for a modular design of a data centre and a technique for simulating each module's energy consumption are presented. Detailed power consumption modelling for each component as well as their interactions are the merits of this model. Unlike existing research, the present modular simulation model can take different design structures of data centres into account and provide us with hourly power consumption profiles for each component. The impacts of environmental parameters such as temperature and humidity are also investigated and incorporated into the model. The flexibility, scalability, comprehensiveness and modularity of this model provides researchers and designers with a powerful tool for energy analysis, management and planning of data centres with different designs and locations.},
	urldate = {2022-04-24},
	journal = {arXiv:1804.00703 [cs]},
	author = {Rahmani, R. and Moser, I. and Seyedmahmoudian, M.},
	month = mar,
	year = {2018},
	note = {arXiv: 1804.00703},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{andrae_global_2015,
	title = {On {Global} {Electricity} {Usage} of {Communication} {Technology}: {Trends} to 2030},
	volume = {6},
	issn = {2078-1547},
	shorttitle = {On {Global} {Electricity} {Usage} of {Communication} {Technology}},
	url = {http://www.mdpi.com/2078-1547/6/1/117},
	doi = {10.3390/challe6010117},
	language = {en},
	number = {1},
	urldate = {2022-04-24},
	journal = {Challenges},
	author = {Andrae, Anders and Edler, Tomas},
	month = apr,
	year = {2015},
	pages = {117--157},
}

@article{koot_usage_2021,
	title = {Usage impact on data center electricity needs: {A} system dynamic forecasting model},
	volume = {291},
	issn = {03062619},
	shorttitle = {Usage impact on data center electricity needs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306261921003019},
	doi = {10.1016/j.apenergy.2021.116798},
	language = {en},
	urldate = {2022-04-24},
	journal = {Applied Energy},
	author = {Koot, Martijn and Wijnhoven, Fons},
	month = jun,
	year = {2021},
	pages = {116798},
}

@inproceedings{steil_backpropagation-decorrelation_2004,
	address = {Budapest, Hungary},
	title = {Backpropagation-decorrelation: online recurrent learning with {O}({N}) complexity},
	volume = {2},
	isbn = {978-0-7803-8359-3},
	shorttitle = {Backpropagation-decorrelation},
	url = {http://ieeexplore.ieee.org/document/1380039/},
	doi = {10.1109/IJCNN.2004.1380039},
	urldate = {2022-04-17},
	booktitle = {2004 {IEEE} {International} {Joint} {Conference} on {Neural} {Networks} ({IEEE} {Cat}. {No}.{04CH37541})},
	publisher = {IEEE},
	author = {Steil, J.J.},
	year = {2004},
	pages = {843--848},
}

@book{mancuso_revolutionary_2018,
	address = {New York, NY},
	edition = {First Atria books hardcover edition},
	title = {The revolutionary genius of plants: a new understanding of plant intelligence and behavior},
	isbn = {978-1-5011-8785-8},
	shorttitle = {The revolutionary genius of plants},
	abstract = {"Do plants have intelligence? Do they have memory? Are they better problem solvers than people? Plants make up 80 percent of the weight of all living things on earth, and yet it is easy to forget that these innocuous, beautiful organisms are responsible for not only the air we breathe, but for many of our modern comforts: our medicine, food, even our fossil fuels. Now, Stefano Mancuso, one of the world's foremost experts on plant neurobiology, reveals the surprisingly sophisticated ability of plants to innovate, to remember, and to learn, highlighting the creative solutions plants offer to the most vexing technological and ecological problems that face us today. Despite not having brains or central nervous systems, plants perceive their surroundings with an even greater sensitivity than animals. They efficiently explore and react promptly to potentially damaging external events thanks to their cooperative, shared systems; without any central command centers, they are able to remember prior catastrophic events and to actively adapt to new ones. [This book] is packed with eye-opening research that makes it more and more clear how remarkable our fellow inhabitants on this planet really are. Consider the Victoria amazonica, whose leaf arrangement allows it to grow to more than two feet in diameter while floating on water, a unique construction that has inspired the design of numerous landmark human structures, from Victorian London's Crystal Palace to Eero Saarinen's graceful Terminal 5 at New York's JFK airport. Or, the tree genus Acacia in Africa and Latin America, which uses its addictive extrafloral nectar to mobilize an army of ants in its defense against predators, even those as large as an elephant. Or, the Boquila trifoliolata--the most accomplished mimic in nature--a vine that can change the size, shape, and color of its leaves to copy the leaves of the host species it climbs, even mimicking two or three other types of leaves at the same time. Making the complicated science of plants wonderfully accessible, The Revolutionary Genius of Plants opens our minds to a new understanding of life on earth."--},
	language = {eng},
	publisher = {Atria Books, an imprint of Simon \& Schuster, Inc},
	author = {Mancuso, Stefano},
	year = {2018},
	note = {OCLC: on1048600309},
	keywords = {plantIntelligence, plantPhysiology},
}

@misc{hemming_why_nodate,
	title = {Why autonomous greenhouses?},
	url = {https://www.wur.nl/en/project/Why-autonomous-greenhouses.htm},
	urldate = {2022-04-15},
	journal = {Wageningen University \& Research},
	author = {Hemming, Silke},
}

@book{european_commission_directorate_general_for_research_and_innovation_resilience_2020,
	address = {LU},
	title = {Resilience and transformation: report of the 5th {SCAR} {Foresight} exercise expert group : natural resources and food systems : transitions towards a ‘safe and just’ operating space.},
	shorttitle = {Resilience and transformation},
	url = {https://data.europa.eu/doi/10.2777/717705},
	language = {eng},
	urldate = {2022-04-15},
	publisher = {Publications Office},
	author = {European Commission, Directorate General for Research {and} Innovation},
	year = {2020},
}

@book{european_commission_directorate_general_for_research_and_innovation_new_2009,
	address = {LU},
	title = {New challenges for agricultural research :climate change, food security, rural development, agricultural knowledge system. 2nd foresight exercise.},
	shorttitle = {New challenges for agricultural research},
	url = {https://data.europa.eu/doi/10.2777/6185},
	language = {eng},
	urldate = {2022-04-15},
	publisher = {Publications Office},
	author = {European Commission, Directorate General for Research {and} Innovation},
	year = {2009},
}

@article{de_swaef_plant_2015-1,
	title = {{PLANT} {SENSORS} {HELP} {TO} {UNDERSTAND} {TIPBURN} {IN} {LETTUCE}},
	issn = {0567-7572, 2406-6168},
	url = {https://www.actahort.org/books/1099/1099_3.htm},
	doi = {10.17660/ActaHortic.2015.1099.3},
	number = {1099},
	urldate = {2022-04-16},
	journal = {Acta Horticulturae},
	author = {De Swaef, T. and Vermeulen, K. and Vergote, N. and Van Lommel, J. and Van Labeke, M.-C. and Bleyaert, P. and Steppe, K.},
	month = sep,
	year = {2015},
	pages = {63--70},
}

@article{alarcon_substantial_1994,
	title = {Substantial hydraulic signals are triggered by leaf-biting insects in tomato},
	volume = {45},
	issn = {0022-0957, 1460-2431},
	url = {https://academic.oup.com/jxb/article-lookup/doi/10.1093/jxb/45.7.953},
	doi = {10.1093/jxb/45.7.953},
	language = {en},
	number = {7},
	urldate = {2022-04-16},
	journal = {Journal of Experimental Botany},
	author = {Alarcon, J-J. and Malone, M.},
	year = {1994},
	pages = {953--957},
}

@article{hurtado-uria_relationships_2013,
	title = {Relationships between meteorological data and grass growth over time in the south of {Ireland}},
	volume = {46},
	issn = {0075-0778, 1939-4055},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00750778.2013.865364},
	doi = {10.1080/00750778.2013.865364},
	language = {en},
	number = {3},
	urldate = {2022-04-16},
	journal = {Irish Geography},
	author = {Hurtado-Uria, Cristina and Hennessy, Deirdre and Shalloo, Laurence and O'Connor, Declan and Delaby, Luc},
	month = nov,
	year = {2013},
	pages = {175--201},
}

@article{poorter_pampered_2016,
	title = {Pampered inside, pestered outside? {Differences} and similarities between plants growing in controlled conditions and in the field},
	volume = {212},
	issn = {0028-646X, 1469-8137},
	shorttitle = {Pampered inside, pestered outside?},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/nph.14243},
	doi = {10.1111/nph.14243},
	language = {en},
	number = {4},
	urldate = {2022-04-15},
	journal = {New Phytologist},
	author = {Poorter, Hendrik and Fiorani, Fabio and Pieruschka, Roland and Wojciechowski, Tobias and Putten, Wim H. and Kleyer, Michael and Schurr, Uli and Postma, Johannes},
	month = dec,
	year = {2016},
	pages = {838--855},
}

@article{walter_plant_2015,
	title = {Plant phenotyping: from bean weighing to image analysis},
	volume = {11},
	issn = {1746-4811},
	shorttitle = {Plant phenotyping},
	url = {http://www.plantmethods.com/content/11/1/14},
	doi = {10.1186/s13007-015-0056-8},
	language = {en},
	number = {1},
	urldate = {2022-04-15},
	journal = {Plant Methods},
	author = {Walter, Achim and Liebisch, Frank and Hund, Andreas},
	year = {2015},
	pages = {14},
}

@techreport{hatfield_ch_2014,
	title = {Ch. 6: {Agriculture}. {Climate} {Change} {Impacts} in the {United} {States}: {The} {Third} {National} {Climate} {Assessment}},
	shorttitle = {Ch. 6},
	url = {https://nca2014.globalchange.gov/downloads},
	urldate = {2022-04-15},
	institution = {U.S. Global Change Research Program},
	author = {Hatfield, J. and Takle, G. and Grotjahn, R. and Holden, P. and Izaurralde, R. C. and Mader, T. and Marshall, E. and Liverman, D. and Melillo, J.M. and Richmond, Terese (T.C.) and Yohe, G. W.},
	year = {2014},
	doi = {10.7930/J02Z13FR},
}

@book{bisoffi_meta-analysis_2019,
	title = {A meta-analysis of recent foresight documents in support of the 5th {SCAR} {Foresight} {Exercise}},
	url = {https://scar-europe.org/images/FORESIGHT/CASA-Study-Meta-Analysis-Foresight-SUB.pdf},
	urldate = {2022-04-15},
	publisher = {Standing Committee on Agricultural Research (SCAR)},
	author = {Bisoffi, Stefano},
	year = {2019},
}

@phdthesis{pieters_reservoir_2022,
	title = {Reservoir computing with plants},
	url = {http://hdl.handle.net/1854/LU-8739713},
	abstract = {Planten zijn complexe organismen, onderhevig aan een groot aantal omgevingsvariabelen,
dewelke op hun beurt de fysiologie en het fenotype van de plant beïnvloeden. In ons werk
wordt dit complex ingangsgedreven systeem beschouwd als een reservoir in physical
reservoir computing (PRC). PRC is een paradigma uit de computerwetenschappen dat een
fysisch substraat gebruikt als rekenmedium. In een eerste luik van het doctoraat werd de
toepasbaarheid van hyperspectrale camera's onderzocht. Dergelijke camera's blijken niet
geschikt te zijn om subtiele spectrale veranderingen, nodig voor PRC, te detecteren.
Daarop werd een nieuw sensor platform ontwikkeld, specifiek ontworpen om contactsensoren
uit te lezen. Aan de hand van bladdikte sensoren toonden we aan dat planten inderdaad als
reservoir gebruikt kunnen worden voor PRC. Planten waren performanter dan een controle
substraat in het oplossen van eco-fysiologische- en omgevingstaken. We onderzochten ook
controle taken zoals NARMA en een vertragingslijn.
Deze resultaten geven aan dat planten niet geschikt zijn om niet- plantspecifieke taken op
te lossen, maar wel goed presteren in plant- gerelateerde taken. Deze eerste experimentele
demonstratie van PRC met planten is een belangrijke mijlpaal naar een meer holistische
kijk op fenotypering en informatieverwerking door planten.},
	language = {en},
	school = {Ghent University. Faculty of Engineering and Architecture},
	author = {Pieters, Olivier},
	year = {2022},
}

@article{lobet_online_2013,
	title = {An online database for plant image analysis software tools},
	volume = {9},
	issn = {1746-4811},
	url = {http://plantmethods.biomedcentral.com/articles/10.1186/1746-4811-9-38},
	doi = {10.1186/1746-4811-9-38},
	language = {en},
	number = {1},
	urldate = {2022-04-13},
	journal = {Plant Methods},
	author = {Lobet, Guillaume and Draye, Xavier and Périlleux, Claire},
	year = {2013},
	pages = {38},
}

@article{patros_toward_2021,
	title = {Toward {Sustainable} {Serverless} {Computing}},
	volume = {25},
	issn = {1089-7801, 1941-0131},
	url = {https://ieeexplore.ieee.org/document/9646540/},
	doi = {10.1109/MIC.2021.3093105},
	number = {6},
	urldate = {2022-04-13},
	journal = {IEEE Internet Computing},
	author = {Patros, Panos and Spillner, Josef and Papadopoulos, Alessandro V. and Varghese, Blesson and Rana, Omer and Dustdar, Schahram and Dustdar, Schahram},
	month = nov,
	year = {2021},
	pages = {42--50},
}

@article{boudon_v-mango_2020,
	title = {V-{Mango}: a functional–structural model of mango tree growth, development and fruit production},
	volume = {126},
	issn = {0305-7364, 1095-8290},
	shorttitle = {V-{Mango}},
	url = {https://academic.oup.com/aob/article/126/4/745/5835680},
	doi = {10.1093/aob/mcaa089},
	abstract = {Abstract
            
              Background and Aims
              Mango (Mangifera indica L.) is the fifth most widely produced fruit in the world. Its cultivation, mainly in tropical and sub-tropical regions, raises a number of issues such as the irregular fruit production across years, phenological asynchronisms that lead to long periods of pest and disease susceptibility, and the heterogeneity of fruit quality and maturity at harvest. To address these issues, we developed an integrative functional–structural plant model that synthesizes knowledge about the vegetative and reproductive development of the mango tree and opens up the possible simulation of cultivation practices.
            
            
              Methods
              We designed a model of architectural development in order to precisely characterize the intricate developmental processes of the mango tree. The appearance of botanical entities was decomposed into elementary stochastic events describing occurrence, intensity and timing of development. These events were determined by structural (position and fate of botanical entities) and temporal (appearance dates) factors. Daily growth and development of growth units and inflorescences were modelled using empirical distributions and thermal time. Fruit growth was determined using an ecophysiological model that simulated carbon- and water-related processes at the fruiting branch scale.
            
            
              Key Results
              The model simulates the dynamics of the population of growth units, inflorescences and fruits at the tree scale during a growing cycle. Modelling the effects of structural and temporal factors makes it possible to simulate satisfactorily the complex interplays between vegetative and reproductive development. The model allowed the characterization of the susceptibility of mango tree to pests and the investigatation of the influence of tree architecture on fruit growth.
            
            
              Conclusions
              This integrative functional–structural model simulates mango tree vegetative and reproductive development over successive growing cycles, allowing a precise characterization of tree phenology and fruit growth and production. The next step is to integrate the effects of cultivation practices, such as pruning, into the model.},
	language = {en},
	number = {4},
	urldate = {2022-04-11},
	journal = {Annals of Botany},
	author = {Boudon, Frédéric and Persello, Séverine and Jestin, Alexandra and Briand, Anne-Sarah and Grechi, Isabelle and Fernique, Pierre and Guédon, Yann and Léchaudel, Mathieu and Lauri, Pierre-Éric and Normand, Frédéric},
	month = sep,
	year = {2020},
	pages = {745--763},
}

@misc{noauthor_groimp_2011,
	title = {{GroIMP}},
	url = {http://wwwuser.gwdg.de/~groimp/grogra.de/software/groimp/index.html},
	publisher = {Department Ecoinformatics, Biometrics and Forest Growth, Georg-August University of Göttingen},
	year = {2011},
}

@misc{fournier_caribu_2016,
	title = {Caribu ({OpenAlea})},
	url = {https://github.com/openalea-incubator/caribu},
	abstract = {Caribu is a modelling suite for lighting 3D virtual scenes, especially designed for the illumination of virtual plant canopies such as virtual crop fields. It uses a special algorithm, the nested radiosity (Chelle et al., 1998), that allows for a precise estimation of light absorption at the level of small canopy elements (typically 1 cm2). It takes into account multiple scattering, allows for infinitisation of the scene (by virtual replication) and performs in a reasonable time (typically a few minutes).},
	author = {Fournier, Christian and Chelle, M and Pradal, Christophe},
	year = {2016},
}

@article{renton_modelling_2017,
	title = {Modelling crop-weed competition: {Why}, what, how and what lies ahead?},
	volume = {95},
	issn = {02612194},
	shorttitle = {Modelling crop-weed competition},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0261219416302472},
	doi = {10.1016/j.cropro.2016.09.003},
	language = {en},
	urldate = {2022-04-11},
	journal = {Crop Protection},
	author = {Renton, Michael and Chauhan, Bhagirath Singh},
	month = may,
	year = {2017},
	pages = {101--108},
}

@incollection{university_of_reading_uk_advances_2021,
	title = {Advances in root architectural modeling},
	isbn = {978-1-78676-360-0},
	url = {https://shop.bdspublishing.com/store/bds/detail/product/3-190-9781786769893},
	abstract = {Root architectural (RSA) models have become important tools in root research and plant phenotyping for studying root traits, processes, and interactions with the environment. The models have been used to simulate how various root traits and processes influence water and nutrient uptake. At a more technical level, they have been used to develop phenotyping technology, particularly for testing algorithms for segmenting roots. To compute these quantitative estimates regarding plant nutrition and root functioning, much development occurred in the last decade increasing the complexity of the models. This chapter describes first the application of the models to questions in plant biology, breeding, and agronomy, and second the development of the models. It concludes with a small outlook suggesting that models need benchmarking and validation and that new developments are likely to include better descriptions of root plasticity responses and focus on biological interactions among (soil) organisms, including mycorrhizal fungi.},
	urldate = {2022-04-11},
	booktitle = {Burleigh {Dodds} {Series} in {Agricultural} {Science}},
	publisher = {Burleigh Dodds Science Publishing},
	author = {{Forschungszentrum Jülich, Germany} and Postma, Johannes A. and Black, Christopher K. and {The Pennsylvania State University, USA}},
	collaborator = {{University of Reading, UK} and Gregory, Peter},
	month = jan,
	year = {2021},
	doi = {10.19103/AS.2020.0075.02},
	pages = {3--32},
}

@article{millar_practical_2019,
	title = {Practical steps to digital organism models, from laboratory model species to ‘{Crops} in silico},
	volume = {70},
	issn = {0022-0957, 1460-2431},
	url = {https://academic.oup.com/jxb/article/70/9/2403/5273976},
	doi = {10.1093/jxb/ery435},
	language = {en},
	number = {9},
	urldate = {2022-04-11},
	journal = {Journal of Experimental Botany},
	author = {Millar, Andrew J and Urquiza, Uriel and Freeman, Peter L and Hume, Alastair and Plotkin, Gordon D and Sorokina, Oxana and Zardilis, Argyris and Zielinski, Tomasz},
	month = apr,
	year = {2019},
	pages = {2403--2418},
}

@article{chang_systems_2019,
	title = {Systems models, phenomics and genomics: three pillars for developing high-yielding photosynthetically efficient crops},
	volume = {1},
	issn = {2517-5025},
	shorttitle = {Systems models, phenomics and genomics},
	url = {https://academic.oup.com/insilicoplants/article/doi/10.1093/insilicoplants/diy003/5479572},
	doi = {10.1093/insilicoplants/diy003},
	language = {en},
	number = {1},
	urldate = {2022-04-11},
	journal = {in silico Plants},
	author = {Chang, Tian-Gen and Chang, Shuoqi and Song, Qing-Feng and Perveen, Shahnaz and Zhu, Xin-Guang},
	month = jan,
	year = {2019},
}

@article{zhu_plants_2016,
	title = {Plants \textit{in silico} : why, why now and what?-an integrative platform for plant systems biology research: {Plants} \textit{in silico}},
	volume = {39},
	issn = {01407791},
	shorttitle = {Plants \textit{in silico}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/pce.12673},
	doi = {10.1111/pce.12673},
	language = {en},
	number = {5},
	urldate = {2022-04-11},
	journal = {Plant, Cell \& Environment},
	author = {Zhu, Xin-Guang and Lynch, Jonathan P. and LeBauer, David S. and Millar, Andrew J. and Stitt, Mark and Long, Stephen P.},
	month = may,
	year = {2016},
	pages = {1049--1057},
}

@article{cieslak_integrating_2016,
	title = {Integrating {Physiology} and {Architecture} in {Models} of {Fruit} {Expansion}},
	volume = {7},
	issn = {1664-462X},
	url = {http://journal.frontiersin.org/article/10.3389/fpls.2016.01739/full},
	doi = {10.3389/fpls.2016.01739},
	urldate = {2022-04-11},
	journal = {Frontiers in Plant Science},
	author = {Cieslak, Mikolaj and Cheddadi, Ibrahim and Boudon, Frédéric and Baldazzi, Valentina and Génard, Michel and Godin, Christophe and Bertin, Nadia},
	month = nov,
	year = {2016},
}

@article{schneider_light_2019,
	title = {Light {Regulation} of {Axillary} {Bud} {Outgrowth} {Along} {Plant} {Axes}: {An} {Overview} of the {Roles} of {Sugars} and {Hormones}},
	volume = {10},
	issn = {1664-462X},
	shorttitle = {Light {Regulation} of {Axillary} {Bud} {Outgrowth} {Along} {Plant} {Axes}},
	url = {https://www.frontiersin.org/article/10.3389/fpls.2019.01296/full},
	doi = {10.3389/fpls.2019.01296},
	urldate = {2022-04-11},
	journal = {Frontiers in Plant Science},
	author = {Schneider, Anne and Godin, Christophe and Boudon, Frédéric and Demotes-Mainard, Sabine and Sakr, Soulaiman and Bertheloot, Jessica},
	month = oct,
	year = {2019},
	pages = {1296},
}

@article{barillot_cn-wheat_2016,
	title = {{CN}-{Wheat}, a functional–structural model of carbon and nitrogen metabolism in wheat culms after anthesis. {II}. {Model} evaluation},
	volume = {118},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article-lookup/doi/10.1093/aob/mcw144},
	doi = {10.1093/aob/mcw144},
	language = {en},
	number = {5},
	urldate = {2022-03-19},
	journal = {Annals of Botany},
	author = {Barillot, Romain and Chambon, Camille and Andrieu, Bruno},
	month = oct,
	year = {2016},
	pages = {1015--1031},
}

@article{barillot_cn-wheat_2016-1,
	title = {{CN}-{Wheat}, a functional–structural model of carbon and nitrogen metabolism in wheat culms after anthesis. {I}. {Model} description},
	volume = {118},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article-lookup/doi/10.1093/aob/mcw143},
	doi = {10.1093/aob/mcw143},
	language = {en},
	number = {5},
	urldate = {2022-03-19},
	journal = {Annals of Botany},
	author = {Barillot, Romain and Chambon, Camille and Andrieu, Bruno},
	month = oct,
	year = {2016},
	pages = {997--1013},
}

@book{swyx_coding_2020,
	title = {The {Coding} {Career} {Handbook}: {Guides}, {Principles}, {Strategies} and {Tactics} from {Code} {Newbie} to {Senior} {Dev}},
	url = {https://www.learninpublic.org/},
	author = {swyx},
	year = {2020},
}

@book{clear_atomic_2018,
	address = {London},
	title = {Atomic habits: an easy \& proven way to build good habits \& break bad ones: tiny changes, remarkable results},
	isbn = {978-1-84794-183-1},
	shorttitle = {Atomic habits},
	language = {eng},
	publisher = {Random House Business},
	author = {Clear, James},
	year = {2018},
}

@article{shannon_communication_1949,
	title = {Communication in the {Presence} of {Noise}},
	volume = {37},
	issn = {0096-8390},
	url = {http://ieeexplore.ieee.org/document/1697831/},
	doi = {10.1109/JRPROC.1949.232969},
	number = {1},
	urldate = {2022-02-16},
	journal = {Proceedings of the IRE},
	author = {Shannon, C.E.},
	month = jan,
	year = {1949},
	pages = {10--21},
}

@article{sinoquet_ratp_2001,
	title = {{RATP}: a model for simulating the spatial distribution of radiation absorption, transpiration and photosynthesis within canopies: application to an isolated tree crown: {3D} model of radiation, photosynthesis and transpiration},
	volume = {24},
	issn = {01407791},
	shorttitle = {{RATP}},
	url = {http://doi.wiley.com/10.1046/j.1365-3040.2001.00694.x},
	doi = {10.1046/j.1365-3040.2001.00694.x},
	language = {en},
	number = {4},
	urldate = {2022-02-10},
	journal = {Plant, Cell \& Environment},
	author = {Sinoquet, H. and Le Roux, X. and Adam, B. and Ameglio, T. and Daudet, F. A.},
	month = apr,
	year = {2001},
	pages = {395--406},
}

@article{tilly_multitemporal_2014,
	title = {Multitemporal crop surface models: accurate plant height measurement and biomass estimation with terrestrial laser scanning in paddy rice},
	volume = {8},
	issn = {1931-3195},
	shorttitle = {Multitemporal crop surface models},
	url = {http://remotesensing.spiedigitallibrary.org/article.aspx?doi=10.1117/1.JRS.8.083671},
	doi = {10.1117/1.JRS.8.083671},
	language = {en},
	number = {1},
	urldate = {2022-02-10},
	journal = {Journal of Applied Remote Sensing},
	author = {Tilly, Nora and Hoffmeister, Dirk and Cao, Qiang and Huang, Shanyu and Lenz-Wiedemann, Victoria and Miao, Yuxin and Bareth, Georg},
	month = mar,
	year = {2014},
	pages = {083671},
}

@article{porter_afrcwheat2_1993,
	title = {{AFRCWHEAT2}: {A} model of the growth and development of wheat incorporating responses to water and nitrogen},
	volume = {2},
	issn = {11610301},
	shorttitle = {{AFRCWHEAT2}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1161030114801366},
	doi = {10.1016/S1161-0301(14)80136-6},
	language = {en},
	number = {2},
	urldate = {2022-02-10},
	journal = {European Journal of Agronomy},
	author = {Porter, John R.},
	year = {1993},
	pages = {69--82},
}

@article{lobet_image_2017,
	title = {Image {Analysis} in {Plant} {Sciences}: {Publish} {Then} {Perish}},
	volume = {22},
	issn = {13601385},
	shorttitle = {Image {Analysis} in {Plant} {Sciences}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1360138517300912},
	doi = {10.1016/j.tplants.2017.05.002},
	language = {en},
	number = {7},
	urldate = {2022-02-10},
	journal = {Trends in Plant Science},
	author = {Lobet, Guillaume},
	month = jul,
	year = {2017},
	pages = {559--566},
}

@article{hafizovic_cmos-based_2007,
	title = {A {CMOS}-based microelectrode array for interaction with neuronal cultures},
	volume = {164},
	issn = {01650270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027007001781},
	doi = {10.1016/j.jneumeth.2007.04.006},
	language = {en},
	number = {1},
	urldate = {2022-02-09},
	journal = {Journal of Neuroscience Methods},
	author = {Hafizovic, S. and Heer, F. and Ugniwenko, T. and Frey, U. and Blau, A. and Ziegler, C. and Hierlemann, A.},
	month = aug,
	year = {2007},
	pages = {93--106},
}

@article{hinaut_real-time_2013,
	title = {Real-{Time} {Parallel} {Processing} of {Grammatical} {Structure} in the {Fronto}-{Striatal} {System}: {A} {Recurrent} {Network} {Simulation} {Study} {Using} {Reservoir} {Computing}},
	volume = {8},
	issn = {1932-6203},
	shorttitle = {Real-{Time} {Parallel} {Processing} of {Grammatical} {Structure} in the {Fronto}-{Striatal} {System}},
	url = {https://dx.plos.org/10.1371/journal.pone.0052946},
	doi = {10.1371/journal.pone.0052946},
	language = {en},
	number = {2},
	urldate = {2022-02-09},
	journal = {PLoS ONE},
	author = {Hinaut, Xavier and Dominey, Peter Ford},
	editor = {Boraud, Thomas},
	month = feb,
	year = {2013},
	pages = {e52946},
}

@article{didovyk_distributed_2015,
	title = {Distributed {Classifier} {Based} on {Genetically} {Engineered} {Bacterial} {Cell} {Cultures}},
	volume = {4},
	issn = {2161-5063, 2161-5063},
	url = {https://pubs.acs.org/doi/10.1021/sb500235p},
	doi = {10.1021/sb500235p},
	language = {en},
	number = {1},
	urldate = {2022-02-09},
	journal = {ACS Synthetic Biology},
	author = {Didovyk, Andriy and Kanakov, Oleg I. and Ivanchenko, Mikhail V. and Hasty, Jeff and Huerta, Ramón and Tsimring, Lev},
	month = jan,
	year = {2015},
	pages = {72--82},
}

@inproceedings{jones_is_2007,
	address = {Honolulu, HI, USA},
	title = {Is there a {Liquid} {State} {Machine} in the {Bacterium} {Escherichia} {Coli}?},
	isbn = {978-1-4244-0701-9},
	url = {http://ieeexplore.ieee.org/document/4218885/},
	doi = {10.1109/ALIFE.2007.367795},
	urldate = {2022-02-09},
	booktitle = {2007 {IEEE} {Symposium} on {Artificial} {Life}},
	publisher = {IEEE},
	author = {Jones, Ben and Stekel, Dov and Rowe, Jon and Fernando, Chrisantha},
	month = apr,
	year = {2007},
	pages = {187--191},
}

@inproceedings{caluwaerts_body_2011,
	title = {The body as a reservoir: locomotion and sensing with linear feedback},
	url = {https://biblio.ugent.be/publication/1203118},
	booktitle = {Conference proceedings : 2nd international conference on morphological computation},
	author = {Caluwaerts, Ken and Schrauwen, Benjamin},
	year = {2011},
}

@article{torrejon_neuromorphic_2017,
	title = {Neuromorphic computing with nanoscale spintronic oscillators},
	volume = {547},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature23011},
	doi = {10.1038/nature23011},
	language = {en},
	number = {7664},
	urldate = {2022-02-09},
	journal = {Nature},
	author = {Torrejon, Jacob and Riou, Mathieu and Araujo, Flavio Abreu and Tsunegi, Sumito and Khalsa, Guru and Querlioz, Damien and Bortolotti, Paolo and Cros, Vincent and Yakushiji, Kay and Fukushima, Akio and Kubota, Hitoshi and Yuasa, Shinji and Stiles, Mark D. and Grollier, Julie},
	month = jul,
	year = {2017},
	pages = {428--431},
}

@article{walter_neuromorphic_2015,
	title = {Neuromorphic implementations of neurobiological learning algorithms for spiking neural networks},
	volume = {72},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608015001410},
	doi = {10.1016/j.neunet.2015.07.004},
	language = {en},
	urldate = {2022-02-09},
	journal = {Neural Networks},
	author = {Walter, Florian and Röhrbein, Florian and Knoll, Alois},
	month = dec,
	year = {2015},
	pages = {152--167},
}

@book{antonik_application_2018,
	address = {New York, NY},
	title = {Application of {FPGA} to real-time machine learning},
	isbn = {978-3-319-91052-9},
	publisher = {Springer Berlin Heidelberg},
	author = {Antonik, Piotr},
	year = {2018},
}

@inproceedings{zhao_novel_2016,
	address = {New York NY USA},
	title = {Novel {Spike} based {Reservoir} {Node} {Design} with {High} {Performance} {Spike} {Delay} {Loop}},
	isbn = {978-1-4503-4061-8},
	url = {https://dl.acm.org/doi/10.1145/2967446.2967447},
	doi = {10.1145/2967446.2967447},
	language = {en},
	urldate = {2022-02-09},
	booktitle = {Proceedings of the 3rd {ACM} {International} {Conference} on {Nanoscale} {Computing} and {Communication}},
	publisher = {ACM},
	author = {Zhao, Chenyuan and Li, Jialing and Liu, Lingjia and Koutha, Lakshmi Sravanthi and Liu, Jian and Yi, Yang},
	month = sep,
	year = {2016},
	pages = {1--5},
}

@article{soriano_minimal_2015,
	title = {Minimal approach to neuro-inspired information processing},
	volume = {9},
	issn = {1662-5188},
	url = {http://journal.frontiersin.org/Article/10.3389/fncom.2015.00068/abstract},
	doi = {10.3389/fncom.2015.00068},
	urldate = {2022-02-09},
	journal = {Frontiers in Computational Neuroscience},
	author = {Soriano, Miguel C. and Brunner, Daniel and Escalona-MorÃ¡n, Miguel and Mirasso, Claudio R. and Fischer, Ingo},
	month = jun,
	year = {2015},
}

@inproceedings{norton_preparing_2006,
	address = {Vancouver, BC, Canada},
	title = {Preparing {More} {Effective} {Liquid} {State} {Machines} {Using} {Hebbian} {Learning}},
	isbn = {978-0-7803-9490-2},
	url = {http://ieeexplore.ieee.org/document/1716685/},
	doi = {10.1109/IJCNN.2006.246996},
	urldate = {2022-02-09},
	booktitle = {The 2006 {IEEE} {International} {Joint} {Conference} on {Neural} {Network} {Proceedings}},
	publisher = {IEEE},
	author = {Norton, D. and Ventura, D.},
	year = {2006},
	pages = {4243--4248},
}

@article{tanaka_effect_2020,
	title = {Effect of recurrent infomax on the information processing capability of input-driven recurrent neural networks},
	volume = {156},
	issn = {01680102},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168010220300821},
	doi = {10.1016/j.neures.2020.02.001},
	language = {en},
	urldate = {2022-02-09},
	journal = {Neuroscience Research},
	author = {Tanaka, Takuma and Nakajima, Kohei and Aoyagi, Toshio},
	month = jul,
	year = {2020},
	pages = {225--233},
}

@article{lukosevicius_reservoir_2009,
	title = {Reservoir computing approaches to recurrent neural network training},
	volume = {3},
	issn = {15740137},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013709000173},
	doi = {10.1016/j.cosrev.2009.03.005},
	language = {en},
	number = {3},
	urldate = {2022-02-09},
	journal = {Computer Science Review},
	author = {Lukoševičius, Mantas and Jaeger, Herbert},
	month = aug,
	year = {2009},
	pages = {127--149},
}

@article{schnepf_crootbox_2018,
	title = {{CRootBox}: a structural–functional modelling framework for root systems},
	volume = {121},
	issn = {0305-7364, 1095-8290},
	shorttitle = {{CRootBox}},
	url = {https://academic.oup.com/aob/article/121/5/1033/4844040},
	doi = {10.1093/aob/mcx221},
	language = {en},
	number = {5},
	urldate = {2022-02-08},
	journal = {Annals of Botany},
	author = {Schnepf, Andrea and Leitner, Daniel and Landl, Magdalena and Lobet, Guillaume and Mai, Trung Hieu and Morandage, Shehan and Sheng, Cheng and Zörner, Mirjam and Vanderborght, Jan and Vereecken, Harry},
	month = apr,
	year = {2018},
	pages = {1033--1053},
}

@article{lang_yggdrasil_2019,
	title = {yggdrasil: a {Python} package for integrating computational models across languages and scales},
	volume = {1},
	issn = {2517-5025},
	shorttitle = {yggdrasil},
	url = {https://academic.oup.com/insilicoplants/article/doi/10.1093/insilicoplants/diz001/5479575},
	doi = {10.1093/insilicoplants/diz001},
	language = {en},
	number = {1},
	urldate = {2022-02-08},
	journal = {in silico Plants},
	author = {Lang, Meagan},
	month = jan,
	year = {2019},
}

@article{de_reffye_two_2021,
	title = {Two decades of research with the {GreenLab} model in agronomy},
	volume = {127},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article/127/3/281/5910892},
	doi = {10.1093/aob/mcaa172},
	abstract = {Abstract
            
              Background
              With up to 200 published contributions, the GreenLab mathematical model of plant growth, developed since 2000 under Sino-French co-operation for agronomic applications, is descended from the structural models developed in the AMAP unit that characterize the development of plants and encompass them in a conceptual mathematical framework. The model also incorporates widely recognized crop model concepts (thermal time, light use efficiency and light interception), adapting them to the level of the individual plant.
            
            
              Scope
              Such long-term research work calls for an overview at some point. That is the objective of this review paper, which retraces the main history of the model’s development and its current status, highlighting three aspects. (1) What are the key features of the GreenLab model? (2) How can the model be a guide for defining relevant measurement strategies and experimental protocols? (3) What kind of applications can such a model address? This last question is answered using case studies as illustrations, and through the Discussion.
            
            
              Conclusions
              The results obtained over several decades illustrate a key feature of the GreenLab model: owing to its concise mathematical formulation based on the factorization of plant structure, it comes along with dedicated methods and experimental protocols for its parameter estimation, in the deterministic or stochastic cases, at single-plant or population levels. Besides providing a reliable statistical framework, this intense and long-term research effort has provided new insights into the internal trophic regulations of many plant species and new guidelines for genetic improvement or optimization of crop systems.},
	language = {en},
	number = {3},
	urldate = {2022-02-08},
	journal = {Annals of Botany},
	author = {de Reffye, Philippe and Hu, Baogang and Kang, Mengzhen and Letort, Véronique and Jaeger, Marc},
	month = feb,
	year = {2021},
	pages = {281--295},
}

@article{godin_functionalstructural_2005,
	title = {Functional–structural plant modelling},
	volume = {166},
	issn = {0028-646X, 1469-8137},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1469-8137.2005.01445.x},
	doi = {10.1111/j.1469-8137.2005.01445.x},
	language = {en},
	number = {3},
	urldate = {2022-02-08},
	journal = {New Phytologist},
	author = {Godin, Christophe and Sinoquet, Hervé},
	month = jun,
	year = {2005},
	pages = {705--708},
}

@article{maass_real-time_2002,
	title = {Real-{Time} {Computing} {Without} {Stable} {States}: {A} {New} {Framework} for {Neural} {Computation} {Based} on {Perturbations}},
	volume = {14},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Real-{Time} {Computing} {Without} {Stable} {States}},
	url = {https://direct.mit.edu/neco/article/14/11/2531-2560/6650},
	doi = {10.1162/089976602760407955},
	abstract = {A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.},
	language = {en},
	number = {11},
	urldate = {2022-01-20},
	journal = {Neural Computation},
	author = {Maass, Wolfgang and Natschläger, Thomas and Markram, Henry},
	month = nov,
	year = {2002},
	pages = {2531--2560},
}

@article{lu_attractor_2018,
	title = {Attractor reconstruction by machine learning},
	volume = {28},
	issn = {1054-1500, 1089-7682},
	url = {http://aip.scitation.org/doi/10.1063/1.5039508},
	doi = {10.1063/1.5039508},
	language = {en},
	number = {6},
	urldate = {2022-01-19},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Lu, Zhixin and Hunt, Brian R. and Ott, Edward},
	month = jun,
	year = {2018},
	pages = {061104},
}

@article{yildiz_re-visiting_2012,
	title = {Re-visiting the echo state property},
	volume = {35},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608012001852},
	doi = {10.1016/j.neunet.2012.07.005},
	language = {en},
	urldate = {2022-01-19},
	journal = {Neural Networks},
	author = {Yildiz, Izzet B. and Jaeger, Herbert and Kiebel, Stefan J.},
	month = nov,
	year = {2012},
	pages = {1--9},
}

@article{maass_real-time_2002-1,
	title = {Real-{Time} {Computing} {Without} {Stable} {States}: {A} {New} {Framework} for {Neural} {Computation} {Based} on {Perturbations}},
	volume = {14},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Real-{Time} {Computing} {Without} {Stable} {States}},
	url = {https://direct.mit.edu/neco/article/14/11/2531-2560/6650},
	doi = {10.1162/089976602760407955},
	abstract = {A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.},
	language = {en},
	number = {11},
	urldate = {2022-01-18},
	journal = {Neural Computation},
	author = {Maass, Wolfgang and Natschläger, Thomas and Markram, Henry},
	month = nov,
	year = {2002},
	pages = {2531--2560},
}

@article{van_der_sande_advances_2017,
	title = {Advances in photonic reservoir computing},
	volume = {6},
	issn = {2192-8614, 2192-8606},
	url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2016-0132/html},
	doi = {10.1515/nanoph-2016-0132},
	abstract = {Abstract
            We review a novel paradigm that has emerged in analogue neuromorphic optical computing. The goal is to implement a reservoir computer in optics, where information is encoded in the intensity and phase of the optical field. Reservoir computing is a bio-inspired approach especially suited for processing time-dependent information. The reservoir’s complex and high-dimensional transient response to the input signal is capable of universal computation. The reservoir does not need to be trained, which makes it very well suited for optics. As such, much of the promise of photonic reservoirs lies in their minimal hardware requirements, a tremendous advantage over other hardware-intensive neural network models. We review the two main approaches to optical reservoir computing: networks implemented with multiple discrete optical nodes and the continuous system of a single nonlinear device coupled to delayed feedback.},
	number = {3},
	urldate = {2022-01-17},
	journal = {Nanophotonics},
	author = {Van der Sande, Guy and Brunner, Daniel and Soriano, Miguel C.},
	month = may,
	year = {2017},
	pages = {561--576},
}

@article{tanaka_recent_2019,
	title = {Recent advances in physical reservoir computing: {A} review},
	volume = {115},
	issn = {08936080},
	shorttitle = {Recent advances in physical reservoir computing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608019300784},
	doi = {10.1016/j.neunet.2019.03.005},
	language = {en},
	urldate = {2022-01-17},
	journal = {Neural Networks},
	author = {Tanaka, Gouhei and Yamane, Toshiyuki and Héroux, Jean Benoit and Nakane, Ryosho and Kanazawa, Naoki and Takeda, Seiji and Numata, Hidetoshi and Nakano, Daiju and Hirose, Akira},
	month = jul,
	year = {2019},
	pages = {100--123},
}

@article{jaeger_harnessing_2004,
	title = {Harnessing {Nonlinearity}: {Predicting} {Chaotic} {Systems} and {Saving} {Energy} in {Wireless} {Communication}},
	volume = {304},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Harnessing {Nonlinearity}},
	url = {https://www.science.org/doi/10.1126/science.1091277},
	doi = {10.1126/science.1091277},
	abstract = {We present a method for learning nonlinear systems, echo state networks (ESNs). ESNs employ artificial recurrent neural networks in a way that has recently been proposed independently as a learning mechanism in biological brains. The learning method is computationally efficient and easy to use. On a benchmark task of predicting a chaotic time series, accuracy is improved by a factor of 2400 over previous techniques. The potential for engineering applications is illustrated by equalizing a communication channel, where the signal error rate is improved by two orders of magnitude.},
	language = {en},
	number = {5667},
	urldate = {2022-01-17},
	journal = {Science},
	author = {Jaeger, Herbert and Haas, Harald},
	month = apr,
	year = {2004},
	pages = {78--80},
}

@book{jaeger_tutorial_2002,
	title = {Tutorial on training recurrent neural networks, covering {BPPT}, {RTRL}, {EKF} and the" echo state network" approach},
	volume = {5},
	publisher = {GMD-Forschungszentrum Informationstechnik Bonn},
	author = {Jaeger, Herbert},
	year = {2002},
	note = {Issue: 01},
}

@article{hendrickson_atomic_1975,
	title = {Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin},
	volume = {66},
	issn = {1090-2104},
	doi = {10.1016/0006-291x(75)90508-2},
	language = {eng},
	number = {4},
	journal = {Biochemical and Biophysical Research Communications},
	author = {Hendrickson, W. A. and Ward, K. B.},
	month = oct,
	year = {1975},
	pmid = {5},
	keywords = {Animals, Cnidaria, Computers, Hemerythrin, Metalloproteins, Models, Molecular, Muscle Proteins, Protein Conformation, Species Specificity},
	pages = {1349--1356},
}

@article{boudon_l-py_2012,
	title = {L-{Py}: {An} {L}-{System} {Simulation} {Framework} for {Modeling} {Plant} {Architecture} {Development} {Based} on a {Dynamic} {Language}},
	volume = {3},
	issn = {1664-462X},
	shorttitle = {L-{Py}},
	url = {http://journal.frontiersin.org/article/10.3389/fpls.2012.00076/abstract},
	doi = {10.3389/fpls.2012.00076},
	urldate = {2022-01-16},
	journal = {Frontiers in Plant Science},
	author = {Boudon, Frédéric and Pradal, Christophe and Cokelaer, Thomas and Prusinkiewicz, Przemyslaw and Godin, Christophe},
	year = {2012},
}

@article{vaillant_towards_2021,
	title = {Towards virtual modeling environments for functional structural plant models based on {Jupyter} notebooks: {Application} to the modeling of mango tree growth and development},
	issn = {2517-5025},
	shorttitle = {Towards virtual modeling environments for functional structural plant models based on {Jupyter} notebooks},
	url = {https://academic.oup.com/insilicoplants/advance-article/doi/10.1093/insilicoplants/diab040/6461084},
	doi = {10.1093/insilicoplants/diab040},
	abstract = {Abstract
            Functional-Structural Plant Models (FSPMs) are powerful tools to explore the complex interplays between plant growth, underlying physiological processes and the environment. Various modeling platforms dedicated to FSPMs have been developed with limited support for collaborative and distributed model design, reproducibility and dissemination. With the objective to alleviate these problems, we used the Jupyter project, an open-source computational notebook ecosystem, to create virtual modeling environments for plant models. These environments combined Python scientific modules, L-systems formalism, multidimensional arrays and 3D plant architecture visualization in Jupyter notebooks. As a case study, we present an application of such an environment by reimplementing V-Mango, a model of mango tree development and fruit production built on interrelated processes of architectural development and fruit growth that are affected by temporal, structural and environmental factors. This new implementation increased model modularity, with modules representing single processes and the workflows between them. The model modularity allowed us to run simulations for a subset of processes only, on simulated or empirical architectures. The exploration of carbohydrate source-sink relationships on a measured mango branch architecture illustrates this possibility. We also proposed solutions for visualization, distant distributed computation and parallel simulations of several independent mango trees during a growing season. The development of models on locations far from computational resources makes collaborative and distributed model design and implementation possible, and demonstrates the usefulness and efficiency of a customizable virtual modeling environment.},
	language = {en},
	urldate = {2022-01-11},
	journal = {in silico Plants},
	author = {Vaillant, Jan and Grechi, Isabelle and Normand, Frédéric and Boudon, Frédéric},
	month = dec,
	year = {2021},
	pages = {diab040},
}

@article{gauthier_functional_2020,
	title = {A functional structural model of grass development based on metabolic regulation and coordination rules},
	volume = {71},
	issn = {0022-0957, 1460-2431},
	url = {https://academic.oup.com/jxb/article/71/18/5454/5851451},
	doi = {10.1093/jxb/eraa276},
	abstract = {Abstract
            Shoot architecture is a key component of the interactions between plants and their environment. We present a novel model of grass, which fully integrates shoot morphogenesis and the metabolism of carbon (C) and nitrogen (N) at organ scale, within a three-dimensional representation of plant architecture. Plant morphogenesis is seen as a self-regulated system driven by two main mechanisms. First, the rate of organ extension and the establishment of architectural traits are regulated by concentrations of C and N metabolites in the growth zones and the temperature. Second, the timing of extension is regulated by rules coordinating successive phytomers instead of a thermal time schedule. Local concentrations are calculated from a model of C and N metabolism at organ scale. The three-dimensional representation allows the accurate calculation of light and temperature distribution within the architecture. The model was calibrated for wheat (Triticum aestivum) and evaluated for early vegetative stages. This approach allowed the simulation of realistic patterns of leaf dimensions, extension dynamics, and organ mass and composition. The model simulated, as emergent properties, plant and agronomic traits. Metabolic activities of growing leaves were investigated in relation to whole-plant functioning and environmental conditions. The current model is an important step towards a better understanding of the plasticity of plant phenotype in different environments.},
	language = {en},
	number = {18},
	urldate = {2022-01-05},
	journal = {Journal of Experimental Botany},
	author = {Gauthier, Marion and Barillot, Romain and Schneider, Anne and Chambon, Camille and Fournier, Christian and Pradal, Christophe and Robert, Corinne and Andrieu, Bruno},
	editor = {Hancock, Robert},
	month = sep,
	year = {2020},
	pages = {5454--5468},
}

@article{prieto_functionalstructural_2020,
	title = {A functional–structural plant model that simulates whole- canopy gas exchange of grapevine plants ({Vitis} vinifera {L}.) under different training systems},
	volume = {126},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article/126/4/647/5677523},
	doi = {10.1093/aob/mcz203},
	abstract = {Abstract
            
              Background and Aims
              Scaling from single-leaf to whole-canopy photosynthesis faces several complexities related to variations in light interception and leaf properties. To evaluate the impact of canopy strucuture on gas exchange, we developed a functional–structural plant model to upscale leaf processes to the whole canopy based on leaf N content. The model integrates different models that calculate intercepted radiation, leaf traits and gas exchange for each leaf in the canopy. Our main objectives were (1) to introduce the gas exchange model developed at the plant level by integrating the leaf-level responses related to canopy structure, (2) to test the model against an independent canopy gas exchange dataset recorded on different plant architectures, and (3) to quantify the impact of intra-canopy N distribution on crop photosynthesis.
            
            
              Methods
              The model combined a 3D reconstruction of grapevine (Vitis vinifera) canopy architecture, a light interception model, and a coupled photosynthesis and stomatal conductance model that considers light-driven variations in N distribution. A portable chamber device was constructed to measure whole-plant gas exchange to validate the model outputs with data collected on different training systems. Finally, a sensitivity analysis was performed to evaluate the impact on C assimilation of different N content distributions within the canopy.
            
            
              Key Results
              By considering a non-uniform leaf N distribution within the canopy, our model accurately reproduced the daily pattern of gas exchange of different canopy architectures. The gain in photosynthesis permitted by the non-uniform compared with a theoretical uniform N distribution was about 18 \%, thereby contributing to the maximization of C assimilation. By contrast, considering a maximal N content for all leaves in the canopy overestimated net CO2 exchange by 28 \% when compared with the non-uniform distribution.
            
            
              Conclusions
              The model reproduced the gas exchange of plants under different training systems with a low error (10 \%). It appears to be a reliable tool to evaluate the impact of a grapevine training system on water use efficiency at the plant level.},
	language = {en},
	number = {4},
	urldate = {2022-01-05},
	journal = {Annals of Botany},
	author = {Prieto, Jorge A and Louarn, Gaetan and Perez Peña, Jorge and Ojeda, Hernán and Simonneau, Thierry and Lebon, Eric},
	month = sep,
	year = {2020},
	pages = {647--660},
}

@inproceedings{pradal_openalea_2015,
	address = {La Jolla California},
	title = {{OpenAlea}: scientific workflows combining data analysis and simulation},
	isbn = {978-1-4503-3709-0},
	shorttitle = {{OpenAlea}},
	url = {https://dl.acm.org/doi/10.1145/2791347.2791365},
	doi = {10.1145/2791347.2791365},
	language = {en},
	urldate = {2022-01-05},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Scientific} and {Statistical} {Database} {Management}},
	publisher = {ACM},
	author = {Pradal, Christophe and Fournier, Christian and Valduriez, Patrick and Cohen-Boulakia, Sarah},
	month = jun,
	year = {2015},
	pages = {1--6},
}

@article{balduzzi_reshaping_2017,
	title = {Reshaping {Plant} {Biology}: {Qualitative} and {Quantitative} {Descriptors} for {Plant} {Morphology}},
	volume = {08},
	issn = {1664-462X},
	shorttitle = {Reshaping {Plant} {Biology}},
	url = {http://journal.frontiersin.org/article/10.3389/fpls.2017.00117/full},
	doi = {10.3389/fpls.2017.00117},
	urldate = {2022-01-05},
	journal = {Frontiers in Plant Science},
	author = {Balduzzi, Mathilde and Binder, Brad M. and Bucksch, Alexander and Chang, Cynthia and Hong, Lilan and Iyer-Pascuzzi, Anjali S. and Pradal, Christophe and Sparks, Erin E.},
	month = feb,
	year = {2017},
}

@article{godin_multiscale_1998,
	title = {A {Multiscale} {Model} of {Plant} {Topological} {Structures}},
	volume = {191},
	issn = {00225193},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022519397905610},
	doi = {10.1006/jtbi.1997.0561},
	language = {en},
	number = {1},
	urldate = {2022-01-05},
	journal = {Journal of Theoretical Biology},
	author = {Godin, C. and Caraglio, Y.},
	month = mar,
	year = {1998},
	pages = {1--46},
}

@techreport{blanc_automatic_2021,
	type = {preprint},
	title = {Automatic calibration of a functional-structural wheat model using an adaptive design and a metamodelling approach},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.07.29.454328},
	abstract = {Abstract
          
            
              
                Background and Aims
                Functional-structural plant models are increasingly being used by plant scientists to address a wide variety of questions. However, the calibration of these complex models is often challenging, mainly because of their high computational cost. In this paper, we applied an automatic method to the calibration of WALTer: a functional-structural wheat model that simulates the plasticity of tillering in response to competition for light.
              
              
                Methods
                We used a Bayesian calibration method to estimate the values of 5 parameters of the WALTer model by fitting the model outputs to tillering dynamics data. The method presented in this paper is based on the Efficient Global Optimisation algorithm. It involves the use of Gaussian process metamodels to generate fast approximations of the model outputs. To account for the uncertainty associated with the metamodels approximations, an adaptive design was used. The efficacy of the method was first assessed using simulated data. The calibration was then applied to experimental data.
              
              
                Key Results
                The method presented here performed well on both simulated and experimental data. In particular, the use of an adaptive design proved to be a very efficient method to improve the quality of the metamodels predictions, especially by reducing the uncertainty in areas of the parameter space that were of interest for the fitting. Moreover, we showed the necessity to have a diversity of field data in order to be able to calibrate the parameters.
              
              
                Conclusions
                The method presented in this paper, based on an adaptive design and Gaussian process metamodels, is an efficient approach for the calibration of WALTer and could be of interest for the calibration of other functional-structural plant models.},
	language = {en},
	urldate = {2022-01-05},
	institution = {Bioinformatics},
	author = {Blanc, Emmanuelle and Enjalbert, Jérôme and Barbillon, Pierre},
	month = jul,
	year = {2021},
	doi = {10.1101/2021.07.29.454328},
}

@article{lecarpentier_walter_2019,
	title = {{WALTer}: a three-dimensional wheat model to study competition for light through the prediction of tillering dynamics},
	volume = {123},
	issn = {0305-7364, 1095-8290},
	shorttitle = {{WALTer}},
	url = {https://academic.oup.com/aob/article/123/6/961/5281415},
	doi = {10.1093/aob/mcy226},
	language = {en},
	number = {6},
	urldate = {2022-01-05},
	journal = {Annals of Botany},
	author = {Lecarpentier, Christophe and Barillot, Romain and Blanc, Emmanuelle and Abichou, Mariem and Goldringer, Isabelle and Barbillon, Pierre and Enjalbert, Jérôme and Andrieu, Bruno},
	month = jun,
	year = {2019},
	pages = {961--975},
}

@article{pradal_openalea_2008,
	title = {{OpenAlea}: a visual programming and component-based software platform for plant modelling},
	volume = {35},
	issn = {1445-4408},
	shorttitle = {{OpenAlea}},
	url = {http://www.publish.csiro.au/?paper=FP08084},
	doi = {10.1071/FP08084},
	abstract = {The development of functional–structural plant models requires an increasing amount of computer modelling. All these models are developed by different teams in various contexts and with different goals. Efficient and flexible computational frameworks are required to augment the interaction between these models, their reusability, and the possibility to compare them on identical datasets. In this paper, we present an open-source platform, OpenAlea, that provides a user-friendly environment for modellers, and advanced deployment methods. OpenAlea allows researchers to build models using a visual programming interface and provides a set of tools and models dedicated to plant modelling. Models and algorithms are embedded in OpenAlea ‘components’ with well defined input and output interfaces that can be easily interconnected to form more complex models and define more macroscopic components. The system architecture is based on the use of a general purpose, high-level, object-oriented script language, Python, widely used in other scientific areas. We present a brief rationale that underlies the architectural design of this system and we illustrate the use of the platform to assemble several heterogeneous model components and to rapidly prototype a complex modelling scenario.},
	language = {en},
	number = {10},
	urldate = {2022-01-05},
	journal = {Functional Plant Biology},
	author = {Pradal, Christophe and Dufour-Kowalski, Samuel and Boudon, Frédéric and Fournier, Christian and Godin, Christophe},
	year = {2008},
	pages = {751},
}

@article{louarn_two_2020,
	title = {Two decades of functional–structural plant modelling: now addressing fundamental questions in systems biology and predictive ecology},
	volume = {126},
	issn = {0305-7364, 1095-8290},
	shorttitle = {Two decades of functional–structural plant modelling},
	url = {https://academic.oup.com/aob/article/126/4/501/5877839},
	doi = {10.1093/aob/mcaa143},
	abstract = {Abstract
            
              Background
              Functional–structural plant models (FSPMs) explore and integrate relationships between a plant’s structure and processes that underlie its growth and development. In the last 20 years, scientists interested in functional–structural plant modelling have expanded greatly the range of topics covered and now handle dynamical models of growth and development occurring from the microscopic scale, and involving cell division in plant meristems, to the macroscopic scales of whole plants and plant communities.
            
            
              Scope
              The FSPM approach occupies a central position in plant science; it is at the crossroads of fundamental questions in systems biology and predictive ecology. This special issue of Annals of Botany features selected papers on critical areas covered by FSPMs and examples of comprehensive models that are used to solve theoretical and applied questions, ranging from developmental biology to plant phenotyping and management of plants for agronomic purposes. Altogether, they offer an opportunity to assess the progress, gaps and bottlenecks along the research path originally foreseen for FSPMs two decades ago. This review also allows discussion of current challenges of FSPMs regarding (1) integration of multidisciplinary knowledge, (2) methods for handling complex models, (3) standards to achieve interoperability and greater genericity and (4) understanding of plant functioning across scales.
            
            
              Conclusions
              This approach has demonstrated considerable progress, but has yet to reach its full potential in terms of integration and heuristic knowledge production. The research agenda of functional–structural plant modellers in the coming years should place a greater emphasis on explaining robust emergent patterns, and on the causes of possible deviation from it. Modelling such patterns could indeed fuel both generic integration across scales and transdisciplinary transfer. In particular, it could be beneficial to emergent fields of research such as model-assisted phenotyping and predictive ecology in managed ecosystems.},
	language = {en},
	number = {4},
	urldate = {2022-01-05},
	journal = {Annals of Botany},
	author = {Louarn, Gaëtan and Song, Youhong},
	month = sep,
	year = {2020},
	pages = {501--509},
}

@article{moulia_fluctuations_2021,
	title = {Fluctuations shape plants through proprioception},
	volume = {372},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.abc6868},
	doi = {10.1126/science.abc6868},
	language = {en},
	number = {6540},
	urldate = {2022-01-05},
	journal = {Science},
	author = {Moulia, Bruno and Douady, Stéphane and Hamant, Olivier},
	month = apr,
	year = {2021},
	pages = {eabc6868},
}

@techreport{ushio_computational_2021,
	type = {preprint},
	title = {Computational capability of ecological dynamics},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.09.15.460556},
	abstract = {Abstract
          
            Ecological dynamics is driven by an ecological network consisting of complex interactions. Information processing capability of artificial networks has been exploited as a computational resource, yet whether an ecological network possesses a computational capability and how we can exploit it remain unclear. Here, we show that ecological dynamics can be exploited as a computational resource. We call this approach “Ecological Reservoir Computing” (ERC) and developed two types of ERC.
            In silico
            ERC reconstructs ecological dynamics from empirical time series and uses simulated system responses as reservoir states, which predicts near future of chaotic dynamics and emulates nonlinear dynamics. The real-time ERC uses population dynamics of a unicellular organism,
            Tetrahymena thermophila
            . Medium temperature is an input signal and changes in population abundance are reservoir states. Intriguingly, the real-time ERC has necessary conditions for reservoir computing and is able to make near future predictions of model and empirical time series.},
	language = {en},
	urldate = {2022-01-05},
	institution = {Ecology},
	author = {Ushio, Masayuki and Watanabe, Kazufumi and Fukuda, Yasuhiro and Tokudome, Yuji and Nakajima, Kohei},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.09.15.460556},
}

@book{chomsky_essential_2008,
	address = {London},
	title = {The essential {Chomsky}},
	isbn = {978-1-84792-064-5},
	language = {eng},
	publisher = {Bodley Head},
	author = {Chomsky, Noam and Arnove, Anthony},
	year = {2008},
}

@book{piketty_capital_2020,
	address = {Cambridge, Massachusetts ; London, England},
	title = {Capital and ideology},
	isbn = {978-0-674-98082-2},
	abstract = {"Thomas Piketty's bestselling Capital in the Twenty-First Century galvanized global debate about inequality. In this audacious follow-up, Piketty challenges us to revolutionize how we think about politics, ideology, and history. He exposes the ideas that have sustained inequality for the past millennium, reveals why the shallow politics of right and left are failing us today, and outlines the structure of a fairer economic system. Our economy, Piketty observes, is not a natural fact. Markets, profits, and capital are all historical constructs that depend on choices. Piketty explores the material and ideological interactions of conflicting social groups that have given us slavery, serfdom, colonialism, communism, and hypercapitalism, shaping the lives of billions. He concludes that the great driver of human progress over the centuries has been the struggle for equality and education and not, as often argued, the assertion of property rights or the pursuit of stability. The new era of extreme inequality that has derailed that progress since the 1980s, he shows, is partly a reaction against communism, but it is also the fruit of ignorance, intellectual specialization, and our drift toward the dead-end politics of identity. Once we understand this, we can begin to envision a more balanced approach to economics and politics. Piketty argues for a new "participatory" socialism, a system founded on an ideology of equality, social property, education, and the sharing of knowledge and power"--},
	language = {fre},
	publisher = {Harvard University Press},
	author = {Piketty, Thomas and Goldhammer, Arthur},
	year = {2020},
	keywords = {Economic aspects, Economics, Equality, Ideology, Political aspects, Property, Social change, Socialism},
}

@book{murakami_1q84_2009,
	address = {Amsterdam},
	title = {1q84: (qutienvierentachtig)},
	isbn = {978-90-254-7162-0},
	shorttitle = {1q84},
	abstract = {De levens van twee solitaire dertigers met een beladen verleden blijken in het Tokio van 1984 op mysterieuze wijze intenser verstrengeld dan ze zelf voor mogelijk houden.},
	language = {Dutch},
	publisher = {Uitgeverij Atlas Contact},
	author = {Murakami, Haruki and Westerhoven, Jacques},
	year = {2009},
	note = {OCLC: 1249026938},
}

@book{van_istendael_mijn_2010,
	address = {Amsterdam},
	title = {Mijn {Duitsland}},
	isbn = {978-90-254-4523-2},
	language = {Dutch},
	publisher = {Pandora},
	author = {Van Istendael, Geert},
	year = {2010},
	note = {OCLC: 697517288},
}

@unpublished{pieters_plants_2021,
	title = {Plants as a {Substrate} for {Physical} {Reservoir} {Computing}},
	language = {en},
	author = {Pieters, Olivier and De Swaef, Tom and Stock, Michiel and wyffels, Francis},
	year = {2021},
}

@book{mishima_decay_2001,
	address = {London},
	title = {The decay of the angel},
	isbn = {978-0-09-928457-4},
	abstract = {The dramatic climax of "The Sea of Fertility" tetraology takes place in the late 1960s. Honda, now an aged and wealthy man, discovers and adopts a sixteen-year-old orphan, Toru, as his heir, identifying him with the tragic protagonists of the three previous novels, each of whom died at the age of twenty. Honda raises and educates the boy, yet watches him, waiting.},
	language = {English},
	publisher = {Vintage},
	author = {Mishima, Yukio},
	year = {2001},
	note = {OCLC: 59529716},
}

@misc{noauthor_notitle_nodate-1,
}

@article{dai_coatnet_2021,
	title = {{CoAtNet}: {Marrying} {Convolution} and {Attention} for {All} {Data} {Sizes}},
	shorttitle = {{CoAtNet}},
	url = {http://arxiv.org/abs/2106.04803},
	abstract = {Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks. In this work, we show that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, we present CoAtNets(pronounced "coat" nets), a family of hybrid models built from two key insights: (1) depthwise Convolution and self-Attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that our CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets: Without extra data, CoAtNet achieves 86.0\% ImageNet top-1 accuracy; When pre-trained with 13M images from ImageNet-21K, our CoAtNet achieves 88.56\% top-1 accuracy, matching ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data; Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88\% top-1 accuracy on ImageNet, establishing a new state-of-the-art result.},
	urldate = {2021-11-04},
	journal = {arXiv:2106.04803 [cs]},
	author = {Dai, Zihang and Liu, Hanxiao and Le, Quoc V. and Tan, Mingxing},
	month = sep,
	year = {2021},
	note = {arXiv: 2106.04803},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{hinton_distilling_2015,
	title = {Distilling the {Knowledge} in a {Neural} {Network}},
	url = {http://arxiv.org/abs/1503.02531},
	abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
	urldate = {2021-11-03},
	journal = {arXiv:1503.02531 [cs, stat]},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.02531},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{bojanowski_advancing_2021,
	title = {Advancing the state of the art in computer vision with self-supervised {Transformers} and 10x more efficient training},
	url = {https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training/},
	language = {en},
	urldate = {2021-01-01},
	journal = {Facebook AI Blog},
	author = {Bojanowski, Piotr and Rabbat, Michael and Joulin, Armand and Ballas, Nicolas and Caron, Mathilde and Assran, Mahmoud},
	month = apr,
	year = {2021},
}

@article{assran_semi-supervised_2021,
	title = {Semi-{Supervised} {Learning} of {Visual} {Features} by {Non}-{Parametrically} {Predicting} {View} {Assignments} with {Support} {Samples}},
	url = {http://arxiv.org/abs/2104.13963},
	abstract = {This paper proposes a novel method of learning by predicting view assignments with support samples (PAWS). The method trains a model to minimize a consistency loss, which ensures that different views of the same unlabeled instance are assigned similar pseudo-labels. The pseudo-labels are generated non-parametrically, by comparing the representations of the image views to those of a set of randomly sampled labeled images. The distance between the view representations and labeled representations is used to provide a weighting over class labels, which we interpret as a soft pseudo-label. By non-parametrically incorporating labeled samples in this way, PAWS extends the distance-metric loss used in self-supervised methods such as BYOL and SwAV to the semi-supervised setting. Despite the simplicity of the approach, PAWS outperforms other semi-supervised methods across architectures, setting a new state-of-the-art for a ResNet-50 on ImageNet trained with either 10\% or 1\% of the labels, reaching 75.5\% and 66.5\% top-1 respectively. PAWS requires 4x to 12x less training than the previous best methods.},
	urldate = {2021-11-01},
	journal = {arXiv:2104.13963 [cs, eess]},
	author = {Assran, Mahmoud and Caron, Mathilde and Misra, Ishan and Bojanowski, Piotr and Joulin, Armand and Ballas, Nicolas and Rabbat, Michael},
	month = jul,
	year = {2021},
	note = {arXiv: 2104.13963},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{caron_emerging_2021,
	title = {Emerging {Properties} in {Self}-{Supervised} {Vision} {Transformers}},
	url = {http://arxiv.org/abs/2104.14294},
	abstract = {In this paper, we question if self-supervised learning provides new properties to Vision Transformer (ViT) that stand out compared to convolutional networks (convnets). Beyond the fact that adapting self-supervised methods to this architecture works particularly well, we make the following observations: first, self-supervised ViT features contain explicit information about the semantic segmentation of an image, which does not emerge as clearly with supervised ViTs, nor with convnets. Second, these features are also excellent k-NN classifiers, reaching 78.3\% top-1 on ImageNet with a small ViT. Our study also underlines the importance of momentum encoder, multi-crop training, and the use of small patches with ViTs. We implement our findings into a simple self-supervised method, called DINO, which we interpret as a form of self-distillation with no labels. We show the synergy between DINO and ViTs by achieving 80.1\% top-1 on ImageNet in linear evaluation with ViT-Base.},
	urldate = {2021-11-01},
	journal = {arXiv:2104.14294 [cs]},
	author = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
	month = may,
	year = {2021},
	note = {arXiv: 2104.14294},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{touvron_training_2021,
	title = {Training data-efficient image transformers \& distillation through attention},
	url = {http://arxiv.org/abs/2012.12877},
	abstract = {Recently, neural networks purely based on attention were shown to address image understanding tasks such as image classification. However, these visual transformers are pre-trained with hundreds of millions of images using an expensive infrastructure, thereby limiting their adoption. In this work, we produce a competitive convolution-free transformer by training on Imagenet only. We train them on a single computer in less than 3 days. Our reference vision transformer (86M parameters) achieves top-1 accuracy of 83.1\% (single-crop evaluation) on ImageNet with no external data. More importantly, we introduce a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention. We show the interest of this token-based distillation, especially when using a convnet as a teacher. This leads us to report results competitive with convnets for both Imagenet (where we obtain up to 85.2\% accuracy) and when transferring to other tasks. We share our code and models.},
	urldate = {2021-11-01},
	journal = {arXiv:2012.12877 [cs]},
	author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jégou, Hervé},
	month = jan,
	year = {2021},
	note = {arXiv: 2012.12877},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2021-11-01},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.11929},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@book{gates_how_2021,
	address = {London},
	title = {How to avoid a climate disaster: the solutions we have and the breakthroughs we need},
	isbn = {978-0-241-44830-4},
	shorttitle = {How to avoid a climate disaster},
	language = {eng},
	publisher = {Allen Lane, an imprint of Penguin Books},
	author = {Gates, Bill},
	year = {2021},
}

@misc{the_apache_software_foundation_apache_nodate,
	title = {Apache {Beam}},
	copyright = {Apache License 2.0},
	url = {https://beam.apache.org/},
	author = {The Apache Software Foundation},
}

@misc{noauthor_leaflet_nodate,
	title = {Leaflet},
	copyright = {BSD-2-Clause License},
	url = {https://github.com/Leaflet/Leaflet},
}

@misc{project_osrm_open_nodate,
	title = {Open {Source} {Routing} {Machine} ({OSRM})},
	copyright = {BSD-2-Clause License},
	url = {http://project-osrm.org/},
	author = {Project OSRM},
}

@misc{noauthor_svelte_nodate,
	title = {Svelte},
	copyright = {MIT License},
	url = {https://svelte.dev/},
}

@misc{noauthor_rickshaw_nodate,
	title = {Rickshaw},
	copyright = {MIT License},
	url = {https://github.com/shutterstock/rickshaw},
}

@misc{noauthor_accurat_nodate,
	title = {Accurat (website)},
	url = {https://www.accurat.ai/},
}

@misc{leitner_plantbox_2020,
	title = {{PlantBox}: {RootSystem} {Tutorial}},
	url = {https://github.com/Plant-Root-Soil-Interactions-Modelling/CPlantBox/blob/master/tutorial.pdf},
	urldate = {2021-10-23},
	author = {Leitner, Daniel},
	year = {2020},
}

@misc{miranda_illustrated_2021,
	type = {personal blog},
	title = {The {Illustrated} {VQGAN}},
	url = {https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/},
	language = {en},
	urldate = {2021-10-21},
	author = {Miranda, Lj},
	month = aug,
	year = {2021},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2021-10-20},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{chen_generative_2020,
	title = {Generative  {Pretraining} {From} {Pixels}},
	author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeff and Jun, Heewoo and Dhariwal, Prafulla and Luan, David and Sutskever, Ilya},
	year = {2020},
}

@article{zhu_transportation_2018,
	title = {Transportation modes behaviour analysis based on raw {GPS} dataset},
	volume = {10},
	issn = {1741-1068, 1741-1076},
	url = {http://www.inderscience.com/link.php?id=90569},
	doi = {10.1504/IJES.2018.090569},
	language = {en},
	number = {2},
	urldate = {2021-10-18},
	journal = {International Journal of Embedded Systems},
	author = {Zhu, Qiuhui and Zhu, Min and Li, Mingzhao and Fu, Min and Huang, Zhibiao and Gan, Qihong and Zhou, Zhenghao},
	year = {2018},
	pages = {126},
}

@article{radford_language_2019,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	url = {https://openai.com/blog/better-language-models/},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	year = {2019},
}

@article{coussement_flexible_2018,
	title = {A flexible geometric model for leaf shape descriptions with high accuracy},
	volume = {52},
	issn = {22424075},
	url = {https://www.silvafennica.fi/article/7740},
	doi = {10.14214/sf.7740},
	number = {2},
	urldate = {2021-10-13},
	journal = {Silva Fennica},
	author = {Coussement, Jonas and Steppe, Kathy and Lootens, Peter and Roldán-Ruiz, Isabel and De Swaef, Tom},
	year = {2018},
}

@article{coussement_modelling_2018,
	title = {Modelling leaf spectral properties in a soybean functional–structural plant model by integrating the prospect radiative transfer model},
	volume = {122},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article/122/4/669/5037755},
	doi = {10.1093/aob/mcy105},
	language = {en},
	number = {4},
	urldate = {2021-10-13},
	journal = {Annals of Botany},
	author = {Coussement, Jonas and Henke, Michael and Lootens, Peter and Roldán-Ruiz, Isabel and Steppe, Kathy and De Swaef, Tom},
	month = sep,
	year = {2018},
	pages = {669--676},
}

@article{coussement_introducing_2018,
	title = {Introducing turgor-driven growth dynamics into functional–structural plant models},
	volume = {121},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article/121/5/849/4793355},
	doi = {10.1093/aob/mcx144},
	language = {en},
	number = {5},
	urldate = {2021-10-13},
	journal = {Annals of Botany},
	author = {Coussement, Jonas R and De Swaef, Tom and Lootens, Peter and Roldán-Ruiz, Isabel and Steppe, Kathy},
	month = apr,
	year = {2018},
	pages = {849--861},
}

@article{coussement_turgor-driven_2020,
	title = {Turgor-driven plant growth applied in a soybean functional–structural plant model},
	volume = {126},
	issn = {0305-7364, 1095-8290},
	url = {https://academic.oup.com/aob/article/126/4/729/5821592},
	doi = {10.1093/aob/mcaa076},
	abstract = {Abstract
            
              Background and Aims
              Turgor pressure within a plant cell represents the key to the mechanistical descriptiion of plant growth, combining the effects of both water and carbon availability. The high level of spatio-temporal variation and diurnal dynamics in turgor pressure within a single plant make it a challenge to model these on the fine spatial scale required for functional–structural plant models (FSPMs). A conceptual model for turgor-driven growth in FSPMs has been established previously, but its practical use has not yet been explored.
            
            
              Methods
              A turgor-driven growth model was incorporated in a newly established FSPM for soybean. The FSPM simulates dynamics in photosynthesis, transpiration and turgor pressure in direct relation to plant growth. Comparisons of simulations with field data were used to evaluate the potential and shortcomings of the modelling approach.
            
            
              Key Results
              Model simulations revealed the need to include an initial seed carbon contribution, a more realistic sink function, an estimation of respiration, and the distinction between osmotic and structural sugars, in order to achieve a realistic model of plant growth. However, differences between simulations and observations remained in individual organ growth patterns and under different environmental conditions. This exposed the need to further investigate the assumptions of developmental and environmental (in)sensitivity of the parameters, which represent physiological and biophysical organ properties in the model, in future research.
            
            
              Conclusions
              The model in its current form is primarily a diagnostic tool, to better understand and model the behaviour of water relations on the scale of individual plant organs throughout the plant life cycle. Potential future applications include its use as a phenotyping tool to capture differences in plant performance between genotypes and growing environments in terms of specific plant characteristics. Additionally, focused experiments can be used to further improve the model mechanisms to lead to better predictive FSPMs, including scenarios of water deficit.},
	language = {en},
	number = {4},
	urldate = {2021-10-13},
	journal = {Annals of Botany},
	author = {Coussement, Jonas R and De Swaef, Tom and Lootens, Peter and Steppe, Kathy},
	month = sep,
	year = {2020},
	pages = {729--744},
}

@incollection{verstraeten_towards_2009,
	title = {Towards generic {Reservoir} {Computing}: time scales and novel reservoirs},
	booktitle = {Reservoir {Computing}: computation with dynamical systems},
	author = {Verstraeten, David},
	year = {2009},
	pages = {73--178},
}

@article{hermans_recurrent_2012,
	title = {Recurrent {Kernel} {Machines}: {Computing} with {Infinite} {Echo} {State} {Networks}},
	volume = {24},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Recurrent {Kernel} {Machines}},
	url = {https://direct.mit.edu/neco/article/24/1/104-133/7730},
	doi = {10.1162/NECO_a_00200},
	abstract = {Echo state networks (ESNs) are large, random recurrent neural networks with a single trained linear readout layer. Despite the untrained nature of the recurrent weights, they are capable of performing universal computations on temporal input data, which makes them interesting for both theoretical research and practical applications. The key to their success lies in the fact that the network computes a broad set of nonlinear, spatiotemporal mappings of the input data, on which linear regression or classification can easily be performed. One could consider the reservoir as a spatiotemporal kernel, in which the mapping to a high-dimensional space is computed explicitly. In this letter, we build on this idea and extend the concept of ESNs to infinite-sized recurrent neural networks, which can be considered recursive kernels that subsequently can be used to create recursive support vector machines. We present the theoretical framework, provide several practical examples of recursive kernels, and apply them to typical temporal tasks.},
	language = {en},
	number = {1},
	urldate = {2021-10-13},
	journal = {Neural Computation},
	author = {Hermans, Michiel and Schrauwen, Benjamin},
	month = jan,
	year = {2012},
	pages = {104--133},
}

@article{lobet_modeling_2014,
	title = {A modeling approach to determine the importance of dynamic regulation of plant hydraulic conductivities on the water uptake dynamics in the soil-plant-atmosphere system},
	volume = {290},
	issn = {03043800},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304380013005735},
	doi = {10.1016/j.ecolmodel.2013.11.025},
	language = {en},
	urldate = {2021-10-11},
	journal = {Ecological Modelling},
	author = {Lobet, Guillaume and Pagès, Loïc and Draye, Xavier},
	month = oct,
	year = {2014},
	pages = {65--75},
}

@article{zhou_cplantbox_2020,
	title = {{CPlantBox}, a whole-plant modelling framework for the simulation of water- and carbon-related processes},
	volume = {2},
	issn = {2517-5025},
	url = {https://academic.oup.com/insilicoplants/article/doi/10.1093/insilicoplants/diaa001/5709632},
	doi = {10.1093/insilicoplants/diaa001},
	abstract = {Abstract
            The interaction between carbon and flows within the vasculature is at the centre of most growth and developmental processes. Understanding how these fluxes influence each other, and how they respond to heterogeneous environmental conditions, is important to answer diverse questions in agricultural and natural ecosystem sciences. However, due to the high complexity of the plant–environment system, specific tools are needed to perform such quantitative analyses. Here, we present CPlantBox, a whole-plant modelling framework based on the root system model CRootBox. CPlantBox is capable of simulating the growth and development of a variety of plant architectures (root and shoot). In addition, the flexibility of CPlantBox enables its coupling with external modelling tools. Here, we connected the model to an existing mechanistic model of water and carbon flows in the plant, PiafMunch. The usefulness of the CPlantBox modelling framework is exemplified in five case studies. Firstly, we illustrate the range of plant structures that can be simulated using CPlantBox. In the second example, we simulated diurnal carbon and water flows, which corroborates published experimental data. In the third case study, we simulated impacts of heterogeneous environment on carbon and water flows. Finally, we showed that our modelling framework can be used to fit phloem pressure and flow speed to (published) experimental data. The CPlantBox modelling framework is open source, highly accessible and flexible. Its aim is to provide a quantitative framework for the understanding of plant–environment interaction.},
	language = {en},
	number = {1},
	urldate = {2021-10-11},
	journal = {in silico Plants},
	author = {Zhou, Xiao-Ran and Schnepf, Andrea and Vanderborght, Jan and Leitner, Daniel and Lacointe, André and Vereecken, Harry and Lobet, Guillaume},
	month = jan,
	year = {2020},
	pages = {diaa001},
}

@article{albasha_hydroshoot_2019,
	title = {{HydroShoot}: a functional-structural plant model for simulating hydraulic structure, gas and energy exchange dynamics of complex plant canopies under water deficit—application to grapevine ({Vitis} vinifera)},
	volume = {1},
	issn = {2517-5025},
	shorttitle = {{HydroShoot}},
	url = {https://academic.oup.com/insilicoplants/article/doi/10.1093/insilicoplants/diz007/5519776},
	doi = {10.1093/insilicoplants/diz007},
	abstract = {Abstract
            This paper presents HydroShoot, a leaf-based functional-structural plant model (FSPM) that simulates gas exchange rates of complex plant canopies under water deficit conditions. HydroShoot is built assuming that simulating both the hydraulic structure of the shoot together with the energy budget of individual leaves is the asset for successfully scaling-up leaf to canopy gas exchange rates. HydroShoot includes three interacting modules: hydraulic, which calculates the distribution of xylem water potential across shoot hydraulic segments; energy, which calculates the complete energy budget of individual leaves; and exchange, which calculates net carbon assimilation and transpiration rates of individual leaves. HydroShoot was evaluated on virtual and real grapevines having strongly contrasted canopies, under well-watered and water deficit conditions. It captured accurately the impact of canopy architecture and soil water status on plant-scale gas exchange rates and leaf-scale temperature and water potential. Both shoot hydraulic structure and leaf energy budget simulations were, as postulated, required to adequately scaling-up leaf to canopy gas exchange rates. Notwithstanding, simulating shoot hydraulic structure was found more necessary to adequately performing this scaling task than simulating leaf energy budget. That is, the intra-canopy variability of leaf water potential was a better predictor of the reduction of whole plant gas exchange rates under water deficit than the intra-canopy variability of leaf temperature. We conclude that simulating the shoot hydraulic structure is a prerequisite if FSPMs are to be used to assess gas exchange rates of complex plant canopies as those of grapevines. Finally, HydroShoot is available through the OpenAlea platform (https://github.com/openalea/hydroshoot) as a set of reusable modules.},
	language = {en},
	number = {1},
	urldate = {2021-10-11},
	journal = {in silico Plants},
	author = {Albasha, R and Fournier, C and Pradal, C and Chelle, M and Prieto, J A and Louarn, G and Simonneau, T and Lebon, E},
	month = jan,
	year = {2019},
	pages = {diz007},
}

@article{koner_relation_2021,
	title = {Relation {Transformer} {Network}},
	url = {http://arxiv.org/abs/2004.06193},
	abstract = {The extraction of a scene graph with objects as nodes and mutual relationships as edges is the basis for a deep understanding of image content. Despite recent advances, such as message passing and joint classification, the detection of visual relationships remains a challenging task due to sub-optimal exploration of the mutual interaction among the visual objects. In this work, we propose a novel transformer formulation for scene graph generation and relation prediction. We leverage the encoder-decoder architecture of the transformer for rich feature embedding of nodes and edges. Specifically, we model the node-to-node interaction with the self-attention of the transformer encoder and the edge-to-node interaction with the cross-attention of the transformer decoder. Further, we introduce a novel positional embedding suitable to handle edges in the decoder. Finally, our relation prediction module classifies the directed relation from the learned node and edge embedding. We name this architecture as Relation Transformer Network (RTN). On the Visual Genome and GQA dataset, we have achieved an overall mean of 4.85\% and 3.1\% point improvement in comparison with state-of-the-art methods. Our experiments show that Relation Transformer can efficiently model context across various datasets with small, medium, and large-scale relation classification.},
	urldate = {2021-10-08},
	journal = {arXiv:2004.06193 [cs]},
	author = {Koner, Rajat and Shit, Suprosanna and Tresp, Volker},
	month = jul,
	year = {2021},
	note = {arXiv: 2004.06193},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ovadia_can_2019,
	title = {Can {You} {Trust} {Your} {Model}'s {Uncertainty}? {Evaluating} {Predictive} {Uncertainty} {Under} {Dataset} {Shift}},
	shorttitle = {Can {You} {Trust} {Your} {Model}'s {Uncertainty}?},
	url = {http://arxiv.org/abs/1906.02530},
	abstract = {Modern machine learning methods including deep learning have achieved great success in predictive accuracy for supervised learning tasks, but may still fall short in giving useful estimates of their predictive \{{\textbackslash}em uncertainty\}. Quantifying uncertainty is especially critical in real-world settings, which often involve input distributions that are shifted from the training distribution due to a variety of factors including sample bias and non-stationarity. In such settings, well calibrated uncertainty estimates convey information about when a model's output should (or should not) be trusted. Many probabilistic deep learning methods, including Bayesian-and non-Bayesian methods, have been proposed in the literature for quantifying predictive uncertainty, but to our knowledge there has not previously been a rigorous large-scale empirical comparison of these methods under dataset shift. We present a large-scale benchmark of existing state-of-the-art methods on classification problems and investigate the effect of dataset shift on accuracy and calibration. We find that traditional post-hoc calibration does indeed fall short, as do several other previous methods. However, some methods that marginalize over models give surprisingly strong results across a broad spectrum of tasks.},
	urldate = {2021-10-08},
	journal = {arXiv:1906.02530 [cs, stat]},
	author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D. and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
	month = dec,
	year = {2019},
	note = {arXiv: 1906.02530},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{esser_taming_2021,
	title = {Taming {Transformers} for {High}-{Resolution} {Image} {Synthesis}},
	url = {http://arxiv.org/abs/2012.09841},
	abstract = {Designed to learn long-range interactions on sequential data, transformers continue to show state-of-the-art results on a wide variety of tasks. In contrast to CNNs, they contain no inductive bias that prioritizes local interactions. This makes them expressive, but also computationally infeasible for long sequences, such as high-resolution images. We demonstrate how combining the effectiveness of the inductive bias of CNNs with the expressivity of transformers enables them to model and thereby synthesize high-resolution images. We show how to (i) use CNNs to learn a context-rich vocabulary of image constituents, and in turn (ii) utilize transformers to efficiently model their composition within high-resolution images. Our approach is readily applied to conditional synthesis tasks, where both non-spatial information, such as object classes, and spatial information, such as segmentations, can control the generated image. In particular, we present the first results on semantically-guided synthesis of megapixel images with transformers and obtain the state of the art among autoregressive models on class-conditional ImageNet. Code and pretrained models can be found at https://github.com/CompVis/taming-transformers .},
	urldate = {2021-10-08},
	journal = {arXiv:2012.09841 [cs]},
	author = {Esser, Patrick and Rombach, Robin and Ommer, Björn},
	month = jun,
	year = {2021},
	note = {arXiv: 2012.09841},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{radford_learning_2021,
	title = {Learning {Transferable} {Visual} {Models} {From} {Natural} {Language} {Supervision}},
	url = {http://arxiv.org/abs/2103.00020},
	abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/OpenAI/CLIP.},
	urldate = {2021-10-08},
	journal = {arXiv:2103.00020 [cs]},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	month = feb,
	year = {2021},
	note = {arXiv: 2103.00020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{ramesh_zero-shot_2021,
	title = {Zero-{Shot} {Text}-to-{Image} {Generation}},
	url = {http://arxiv.org/abs/2102.12092},
	abstract = {Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.},
	urldate = {2021-10-08},
	journal = {arXiv:2102.12092 [cs]},
	author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.12092},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{legenstein_reward-modulated_2010,
	title = {A {Reward}-{Modulated} {Hebbian} {Learning} {Rule} {Can} {Explain} {Experimentally} {Observed} {Network} {Reorganization} in a {Brain} {Control} {Task}},
	volume = {30},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4284-09.2010},
	doi = {10.1523/JNEUROSCI.4284-09.2010},
	language = {en},
	number = {25},
	urldate = {2021-10-03},
	journal = {Journal of Neuroscience},
	author = {Legenstein, R. and Chase, S. M. and Schwartz, A. B. and Maass, W.},
	month = jun,
	year = {2010},
	pages = {8400--8410},
}

@article{tatarchenko_octree_2017,
	title = {Octree {Generating} {Networks}: {Efficient} {Convolutional} {Architectures} for {High}-resolution {3D} {Outputs}},
	shorttitle = {Octree {Generating} {Networks}},
	url = {http://arxiv.org/abs/1703.09438},
	abstract = {We present a deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation. The network learns to predict both the structure of the octree, and the occupancy values of individual cells. This makes it a particularly valuable technique for generating 3D shapes. In contrast to standard decoders acting on regular voxel grids, the architecture does not have cubic complexity. This allows representing much higher resolution outputs with a limited memory budget. We demonstrate this in several application domains, including 3D convolutional autoencoders, generation of objects and whole scenes from high-level representations, and shape from a single image.},
	urldate = {2021-09-30},
	journal = {arXiv:1703.09438 [cs]},
	author = {Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},
	month = aug,
	year = {2017},
	note = {arXiv: 1703.09438},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{groueix_papier-mache_2018,
	address = {Salt Lake City, UT, USA},
	title = {A {Papier}-{Mache} {Approach} to {Learning} {3D} {Surface} {Generation}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578128/},
	doi = {10.1109/CVPR.2018.00030},
	urldate = {2021-09-30},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G. and Russell, Bryan C. and Aubry, Mathieu},
	month = jun,
	year = {2018},
	pages = {216--224},
}

@article{wang_global--local_2019,
	title = {Global-to-local generative model for {3D} shapes},
	volume = {37},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3272127.3275025},
	doi = {10.1145/3272127.3275025},
	language = {en},
	number = {6},
	urldate = {2021-09-30},
	journal = {ACM Transactions on Graphics},
	author = {Wang, Hao and Schor, Nadav and Hu, Ruizhen and Huang, Haibin and Cohen-Or, Daniel and Huang, Hui},
	month = jan,
	year = {2019},
	pages = {1--10},
}

@inproceedings{chen_aerodynamic_2019,
	address = {San Diego, California},
	title = {Aerodynamic {Design} {Optimization} and {Shape} {Exploration} using {Generative} {Adversarial} {Networks}},
	isbn = {978-1-62410-578-4},
	url = {https://arc.aiaa.org/doi/10.2514/6.2019-2351},
	doi = {10.2514/6.2019-2351},
	language = {en},
	urldate = {2021-09-30},
	booktitle = {{AIAA} {Scitech} 2019 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Chen, Wei and Chiu, Kevin and Fuge, Mark},
	month = jan,
	year = {2019},
}

@article{wang_adaptive_2019,
	title = {Adaptive {O}-{CNN}: a patch-based deep representation of {3D} shapes},
	volume = {37},
	issn = {0730-0301, 1557-7368},
	shorttitle = {Adaptive {O}-{CNN}},
	url = {https://dl.acm.org/doi/10.1145/3272127.3275050},
	doi = {10.1145/3272127.3275050},
	language = {en},
	number = {6},
	urldate = {2021-09-30},
	journal = {ACM Transactions on Graphics},
	author = {Wang, Peng-Shuai and Sun, Chun-Yu and Liu, Yang and Tong, Xin},
	month = jan,
	year = {2019},
	pages = {1--11},
}

@article{wang_inverse_2021,
	title = {An inverse design method for supercritical airfoil based on conditional generative models},
	issn = {10009361},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1000936121000662},
	doi = {10.1016/j.cja.2021.03.006},
	language = {en},
	urldate = {2021-09-30},
	journal = {Chinese Journal of Aeronautics},
	author = {Wang, Jing and Li, Runze and He, Cheng and Chen, Haixin and Cheng, Ran and Zhai, Chen and Zhang, Miao},
	month = mar,
	year = {2021},
	pages = {S1000936121000662},
}

@article{zhang_generative_2021,
	title = {Generative design of decorative architectural parts},
	issn = {0178-2789, 1432-2315},
	url = {https://link.springer.com/10.1007/s00371-021-02142-1},
	doi = {10.1007/s00371-021-02142-1},
	language = {en},
	urldate = {2021-09-30},
	journal = {The Visual Computer},
	author = {Zhang, Yuzhe and Ong, Chan Chi and Zheng, Jianmin and Lie, Seng-Tjhen and Guo, Zhendong},
	month = may,
	year = {2021},
}

@article{wu_sagnet_2019,
	title = {{SAGNet}: structure-aware generative network for {3D}-shape modeling},
	volume = {38},
	issn = {0730-0301, 1557-7368},
	shorttitle = {{SAGNet}},
	url = {https://dl.acm.org/doi/10.1145/3306346.3322956},
	doi = {10.1145/3306346.3322956},
	language = {en},
	number = {4},
	urldate = {2021-09-30},
	journal = {ACM Transactions on Graphics},
	author = {Wu, Zhijie and Wang, Xiang and Lin, Di and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
	month = jul,
	year = {2019},
	pages = {1--14},
}

@article{strubell_energy_2019,
	title = {Energy and {Policy} {Considerations} for {Deep} {Learning} in {NLP}},
	url = {http://arxiv.org/abs/1906.02243},
	abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
	urldate = {2021-09-29},
	journal = {arXiv:1906.02243 [cs]},
	author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02243},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{li_evaluating_2016,
	address = {Atlanta, GA, USA},
	title = {Evaluating the {Energy} {Efficiency} of {Deep} {Convolutional} {Neural} {Networks} on {CPUs} and {GPUs}},
	isbn = {978-1-5090-3936-4},
	url = {http://ieeexplore.ieee.org/document/7723730/},
	doi = {10.1109/BDCloud-SocialCom-SustainCom.2016.76},
	urldate = {2021-09-29},
	booktitle = {2016 {IEEE} {International} {Conferences} on {Big} {Data} and {Cloud} {Computing} ({BDCloud}), {Social} {Computing} and {Networking} ({SocialCom}), {Sustainable} {Computing} and {Communications} ({SustainCom}) ({BDCloud}-{SocialCom}-{SustainCom})},
	publisher = {IEEE},
	author = {Li, Da and Chen, Xinbo and Becchi, Michela and Zong, Ziliang},
	month = oct,
	year = {2016},
	pages = {477--484},
}

@article{anthony_carbontracker_2020,
	title = {Carbontracker: {Tracking} and {Predicting} the {Carbon} {Footprint} of {Training} {Deep} {Learning} {Models}},
	shorttitle = {Carbontracker},
	url = {http://arxiv.org/abs/2007.03051},
	abstract = {Deep learning (DL) can achieve impressive results across a wide variety of tasks, but this often comes at the cost of training models for extensive periods on specialized hardware accelerators. This energy-intensive workload has seen immense growth in recent years. Machine learning (ML) may become a significant contributor to climate change if this exponential trend continues. If practitioners are aware of their energy and carbon footprint, then they may actively take steps to reduce it whenever possible. In this work, we present Carbontracker, a tool for tracking and predicting the energy and carbon footprint of training DL models. We propose that energy and carbon footprint of model development and training is reported alongside performance metrics using tools like Carbontracker. We hope this will promote responsible computing in ML and encourage research into energy-efficient deep neural networks.},
	urldate = {2021-09-29},
	journal = {arXiv:2007.03051 [cs, eess, stat]},
	author = {Anthony, Lasse F. Wolff and Kanding, Benjamin and Selvan, Raghavendra},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.03051},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing, Statistics - Machine Learning},
}

@article{asperti_dissecting_2021,
	title = {Dissecting {FLOPs} along input dimensions for {GreenAI} cost estimations},
	url = {http://arxiv.org/abs/2107.11949},
	abstract = {The term GreenAI refers to a novel approach to Deep Learning, that is more aware of the ecological impact and the computational efficiency of its methods. The promoters of GreenAI suggested the use of Floating Point Operations (FLOPs) as a measure of the computational cost of Neural Networks; however, that measure does not correlate well with the energy consumption of hardware equipped with massively parallel processing units like GPUs or TPUs. In this article, we propose a simple refinement of the formula used to compute floating point operations for convolutional layers, called \{{\textbackslash}alpha\}-FLOPs, explaining and correcting the traditional discrepancy with respect to different layers, and closer to reality. The notion of \{{\textbackslash}alpha\}-FLOPs relies on the crucial insight that, in case of inputs with multiple dimensions, there is no reason to believe that the speedup offered by parallelism will be uniform along all different axes.},
	urldate = {2021-09-29},
	journal = {arXiv:2107.11949 [cs]},
	author = {Asperti, Andrea and Evangelista, Davide and Marzolla, Moreno},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.11949},
	keywords = {68T07, Computer Science - Machine Learning, I.2},
}

@article{yigitcanlar_sustainability_2020,
	title = {The {Sustainability} of {Artificial} {Intelligence}: {An} {Urbanistic} {Viewpoint} from the {Lens} of {Smart} and {Sustainable} {Cities}},
	volume = {12},
	issn = {2071-1050},
	shorttitle = {The {Sustainability} of {Artificial} {Intelligence}},
	url = {https://www.mdpi.com/2071-1050/12/20/8548},
	doi = {10.3390/su12208548},
	abstract = {The popularity and application of artificial intelligence (AI) are increasing rapidly all around the world—where, in simple terms, AI is a technology which mimics the behaviors commonly associated with human intelligence. Today, various AI applications are being used in areas ranging from marketing to banking and finance, from agriculture to healthcare and security, from space exploration to robotics and transport, and from chatbots to artificial creativity and manufacturing. More recently, AI applications have also started to become an integral part of many urban services. Urban artificial intelligences manage the transport systems of cities, run restaurants and shops where every day urbanity is expressed, repair urban infrastructure, and govern multiple urban domains such as traffic, air quality monitoring, garbage collection, and energy. In the age of uncertainty and complexity that is upon us, the increasing adoption of AI is expected to continue, and so its impact on the sustainability of our cities. This viewpoint explores and questions the sustainability of AI from the lens of smart and sustainable cities, and generates insights into emerging urban artificial intelligences and the potential symbiosis between AI and a smart and sustainable urbanism. In terms of methodology, this viewpoint deploys a thorough review of the current status of AI and smart and sustainable cities literature, research, developments, trends, and applications. In so doing, it contributes to existing academic debates in the fields of smart and sustainable cities and AI. In addition, by shedding light on the uptake of AI in cities, the viewpoint seeks to help urban policymakers, planners, and citizens make informed decisions about a sustainable adoption of AI.},
	language = {en},
	number = {20},
	urldate = {2021-09-29},
	journal = {Sustainability},
	author = {Yigitcanlar, Tan and Cugurullo, Federico},
	month = oct,
	year = {2020},
	keywords = {R2},
	pages = {8548},
}

@article{mulligan_ai_2021,
	title = {{AI} ethics: {A} framework for measuring embodied carbon in {AI} systems},
	issn = {2730-5953, 2730-5961},
	shorttitle = {{AI} ethics},
	url = {https://link.springer.com/10.1007/s43681-021-00071-2},
	doi = {10.1007/s43681-021-00071-2},
	abstract = {Abstract
            This paper outlines the ethical implications of AI from a climate perspective. So far, much of the discussion around AI ethics have focused on bias, unexplainable outcomes, privacy and other social impacts of such systems. The role and contribution of AI towards climate change and the ethical implications of its contribution to an unjust distribution of impact on the planet, humans and flora and fauna have not yet been covered in detail within the technical community. Within this paper, we aim to raise some of the issues of AI associated with climate justice and we propose a framework that will allow the AI and ICT industries to measure their true impact on the planet, propose an organisational structure to take this work forward and propose future research areas for this important topic.},
	language = {en},
	urldate = {2021-09-29},
	journal = {AI and Ethics},
	author = {Mulligan, Catherine and Elaluf-Calderwood, Silvia},
	month = jun,
	year = {2021},
	keywords = {R4},
}

@article{van_wynsberghe_sustainable_2021,
	title = {Sustainable {AI}: {AI} for sustainability and the sustainability of {AI}},
	volume = {1},
	issn = {2730-5953, 2730-5961},
	shorttitle = {Sustainable {AI}},
	url = {https://link.springer.com/10.1007/s43681-021-00043-6},
	doi = {10.1007/s43681-021-00043-6},
	abstract = {Abstract
            
              While there is a growing effort towards AI
              for
              Sustainability (e.g. towards the sustainable development goals) it is time to move beyond that and to address the sustainability
              of
              developing and using AI systems. In this paper I propose a definition of Sustainable AI; Sustainable AI is a movement to foster change in the entire lifecycle of AI products (i.e. idea generation, training, re-tuning, implementation, governance) towards greater ecological integrity and social justice. As such, Sustainable AI is focused on more than AI applications; rather, it addresses the whole sociotechnical system of AI. I have suggested here that Sustainable AI is not about how to sustain the development of AI per say but it is about how to develop AI that is compatible with sustaining environmental resources for current and future generations; economic models for societies; and societal values that are fundamental to a given society. I have articulated that the phrase Sustainable AI be understood as having two branches; AI
              for
              sustainability and sustainability
              of
              AI (e.g. reduction of carbon emissions and computing power). I propose that Sustainable AI take sustainable development at the core of its definition with three accompanying tensions between AI innovation and equitable resource distribution; inter and intra-generational justice; and, between environment, society, and economy. This paper is not meant to engage with each of the three pillars of sustainability (i.e. social, economic, environment), and as such the pillars of sustainable AI. Rather, this paper is meant to inspire the reader, the policy maker, the AI ethicist, the AI developer to connect with the environment—to remember that there are environmental costs to AI. Further, to direct funding towards sustainable methods
              of
              AI.},
	language = {en},
	number = {3},
	urldate = {2021-09-29},
	journal = {AI and Ethics},
	author = {van Wynsberghe, Aimee},
	month = aug,
	year = {2021},
	keywords = {R4},
	pages = {213--218},
}

@article{gauthier_next_2021,
	title = {Next generation reservoir computing},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-25801-2},
	doi = {10.1038/s41467-021-25801-2},
	abstract = {Abstract
            Reservoir computing is a best-in-class machine learning algorithm for processing information generated by dynamical systems using observed time-series data. Importantly, it requires very small training data sets, uses linear optimization, and thus requires minimal computing resources. However, the algorithm uses randomly sampled matrices to define the underlying recurrent neural network and has a multitude of metaparameters that must be optimized. Recent results demonstrate the equivalence of reservoir computing to nonlinear vector autoregression, which requires no random matrices, fewer metaparameters, and provides interpretable results. Here, we demonstrate that nonlinear vector autoregression excels at reservoir computing benchmark tasks and requires even shorter training data sets and training time, heralding the next generation of reservoir computing.},
	language = {en},
	number = {1},
	urldate = {2021-09-28},
	journal = {Nature Communications},
	author = {Gauthier, Daniel J. and Bollt, Erik and Griffith, Aaron and Barbosa, Wendson A. S.},
	month = dec,
	year = {2021},
	pages = {5564},
}

@misc{wyffels_project_2021,
	title = {Project {Proposal}: {Plant} {Reservoir} {Computing}},
	author = {wyffels, Francis},
	year = {2021},
}

@incollection{stepney_computers_2018,
	address = {Cham},
	title = {Computers from {Plants} {We} {Never} {Made}: {Speculations}},
	volume = {28},
	isbn = {978-3-319-67996-9 978-3-319-67997-6},
	shorttitle = {Computers from {Plants} {We} {Never} {Made}},
	url = {http://link.springer.com/10.1007/978-3-319-67997-6_17},
	urldate = {2021-09-28},
	booktitle = {Inspired by {Nature}},
	publisher = {Springer International Publishing},
	author = {Adamatzky, Andrew and Harding, Simon and Erokhin, Victor and Mayne, Richard and Gizzie, Nina and Baluška, Frantisek and Mancuso, Stefano and Sirakoulis, Georgios Ch.},
	editor = {Stepney, Susan and Adamatzky, Andrew},
	year = {2018},
	doi = {10.1007/978-3-319-67997-6_17},
	note = {Series Title: Emergence, Complexity and Computation},
	pages = {357--387},
}

@article{caluwaerts_locomotion_2013,
	title = {Locomotion {Without} a {Brain}: {Physical} {Reservoir} {Computing} in {Tensegrity} {Structures}},
	volume = {19},
	issn = {1064-5462, 1530-9185},
	shorttitle = {Locomotion {Without} a {Brain}},
	url = {https://direct.mit.edu/artl/article/19/1/35-66/2755},
	doi = {10.1162/ARTL_a_00080},
	abstract = {Embodiment has led to a revolution in robotics by not thinking of the robot body and its controller as two separate units, but taking into account the interaction of the body with its environment. By investigating the effect of the body on the overall control computation, it has been suggested that the body is effectively performing computations, leading to the term morphological computation. Recent work has linked this to the field of reservoir computing, allowing one to endow morphologies with a theory of universal computation. In this work, we study a family of highly dynamic body structures, called tensegrity structures, controlled by one of the simplest kinds of “brains.” These structures can be used to model biomechanical systems at different scales. By analyzing this extreme instantiation of compliant structures, we demonstrate the existence of a spectrum of choices of how to implement control in the body-brain composite. We show that tensegrity structures can maintain complex gaits with linear feedback control and that external feedback can intrinsically be integrated in the control loop. The various linear learning rules we consider differ in biological plausibility, and no specific assumptions are made on how to implement the feedback in a physical system.},
	language = {en},
	number = {1},
	urldate = {2021-09-25},
	journal = {Artificial Life},
	author = {Caluwaerts, K. and D'Haene, M. and Verstraeten, D. and Schrauwen, B.},
	month = jan,
	year = {2013},
	pages = {35--66},
}

@article{greenham_trip_2015,
	title = {{TRiP}: {Tracking} {Rhythms} in {Plants}, an automated leaf movement analysis program for circadian period estimation},
	volume = {11},
	issn = {1746-4811},
	shorttitle = {{TRiP}},
	url = {http://www.plantmethods.com/content/11/1/33},
	doi = {10.1186/s13007-015-0075-5},
	language = {en},
	number = {1},
	urldate = {2021-08-29},
	journal = {Plant Methods},
	author = {Greenham, Kathleen and Lou, Ping and Remsen, Sara E and Farid, Hany and McClung, C Robertson},
	month = dec,
	year = {2015},
	keywords = {circadianClock, leafMovement},
	pages = {33},
}

@article{wagner_plant_2017,
	title = {The plant leaf movement analyzer ({PALMA}): a simple tool for the analysis of periodic cotyledon and leaf movement in {Arabidopsis} thaliana},
	volume = {13},
	issn = {1746-4811},
	shorttitle = {The plant leaf movement analyzer ({PALMA})},
	url = {http://plantmethods.biomedcentral.com/articles/10.1186/s13007-016-0153-3},
	doi = {10.1186/s13007-016-0153-3},
	language = {en},
	number = {1},
	urldate = {2021-08-29},
	journal = {Plant Methods},
	author = {Wagner, Lucas and Schmal, Christoph and Staiger, Dorothee and Danisman, Selahattin},
	month = dec,
	year = {2017},
	keywords = {circadianClock, leafMovement},
	pages = {2},
}

@article{lukosevicius_reservoir_2012,
	title = {Reservoir {Computing} {Trends}},
	volume = {26},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-012-0204-5},
	doi = {10.1007/s13218-012-0204-5},
	abstract = {Reservoir Computing (RC) is a paradigm of understanding and training Recurrent Neural Networks (RNNs) based on treating the recurrent part (the reservoir) differently than the readouts from it. It started ten years ago and is currently a prolific research area, giving important insights into RNNs, practical machine learning tools, as well as enabling computation with non-conventional hardware. Here we give a brief introduction into basic concepts, methods, insights, current developments, and highlight some applications of RC.},
	language = {en},
	number = {4},
	urldate = {2021-07-19},
	journal = {KI - Künstliche Intelligenz},
	author = {Lukoševičius, Mantas and Jaeger, Herbert and Schrauwen, Benjamin},
	month = nov,
	year = {2012},
	keywords = {introduction, reservoirComputing},
	pages = {365--371},
}

@article{vlachas_backpropagation_2020,
	title = {Backpropagation algorithms and {Reservoir} {Computing} in {Recurrent} {Neural} {Networks} for the forecasting of complex spatiotemporal dynamics},
	volume = {126},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608020300708},
	doi = {10.1016/j.neunet.2020.02.016},
	language = {en},
	urldate = {2021-08-13},
	journal = {Neural Networks},
	author = {Vlachas, P.R. and Pathak, J. and Hunt, B.R. and Sapsis, T.P. and Girvan, M. and Ott, E. and Koumoutsakos, P.},
	month = jun,
	year = {2020},
	keywords = {BPTT, RNN, comparativeStudy, reservoirComputing},
	pages = {191--217},
}

@article{nakajima_physical_2020,
	title = {Physical reservoir computing—an introductory perspective},
	volume = {59},
	issn = {0021-4922, 1347-4065},
	url = {https://iopscience.iop.org/article/10.35848/1347-4065/ab8d4f},
	doi = {10.35848/1347-4065/ab8d4f},
	abstract = {Understanding the fundamental relationships between physics and its information-processing capability has been an active research topic for many years. Physical reservoir computing is a recently introduced framework that allows one to exploit the complex dynamics of physical systems as information-processing devices. This framework is particularly suited for edge computing devices, in which information processing is incorporated at the edge (e.g. into sensors) in a decentralized manner to reduce the adaptation delay caused by data transmission overhead. This paper aims to illustrate the potentials of the framework using examples from soft robotics and to provide a concise overview focusing on the basic motivations for introducing it, which stem from a number of fields, including machine learning, nonlinear dynamical systems, biological science, materials science, and physics.},
	language = {en},
	number = {6},
	urldate = {2021-07-19},
	journal = {Japanese Journal of Applied Physics},
	author = {Nakajima, Kohei},
	month = jun,
	year = {2020},
	keywords = {PRC, introduction, reservoirComputing},
	pages = {060501},
}

@article{burms_reward-modulated_2015,
	title = {Reward-{Modulated} {Hebbian} {Plasticity} as {Leverage} for {Partially} {Embodied} {Control} in {Compliant} {Robotics}},
	volume = {9},
	issn = {1662-5218},
	url = {http://journal.frontiersin.org/Article/10.3389/fnbot.2015.00009/abstract},
	doi = {10.3389/fnbot.2015.00009},
	abstract = {In embodied computation (or morphological computation), part of the complexity of motor control is offloaded to the body dynamics. We demonstrate that a simple Hebbianlike learning rule can be used to train systems with (partial) embodiment, and can be extended outside of the scope of traditional neural networks. To this end, we apply the learning rule to optimize the connection weights of recurrent neural networks with different topologies and for various tasks. We then apply this learning rule to a simulated compliant tensegrity robot by optimizing static feedback controllers that directly exploit the dynamics of the robot body. This leads to partially embodied controllers, i.e., hybrid controllers that naturally integrate the computations that are performed by the robot body into a neural network architecture. Our results demonstrate the universal applicability of reward-modulated Hebbian learning. Furthermore, they demonstrate the robustness of systems trained with the learning rule. This study strengthens our belief that compliant robots should or can be seen as computational units, instead of dumb hardware that needs a complex controller. This link between compliant robotics and neural networks is also the main reason for our search for simple universal learning rules for both neural networks and robotics.},
	language = {en},
	urldate = {2021-07-19},
	journal = {Frontiers in Neurorobotics},
	author = {Burms, Jeroen and Caluwaerts, Ken and Dambre, Joni},
	month = aug,
	year = {2015},
	keywords = {hebbianLearning},
}

@article{nakajima_information_2015,
	title = {Information processing via physical soft body},
	volume = {5},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/srep10487},
	doi = {10.1038/srep10487},
	language = {en},
	number = {1},
	urldate = {2021-08-29},
	journal = {Scientific Reports},
	author = {Nakajima, Kohei and Hauser, Helmut and Li, Tao and Pfeifer, Rolf},
	month = sep,
	year = {2015},
	keywords = {PRC, softBodyRobotics},
	pages = {10487},
}

@article{nakajima_soft_2013,
	title = {A soft body as a reservoir: case studies in a dynamic model of octopus-inspired soft robotic arm},
	volume = {7},
	issn = {1662-5188},
	shorttitle = {A soft body as a reservoir},
	url = {http://journal.frontiersin.org/article/10.3389/fncom.2013.00091/abstract},
	doi = {10.3389/fncom.2013.00091},
	urldate = {2021-08-29},
	journal = {Frontiers in Computational Neuroscience},
	author = {Nakajima, Kohei and Hauser, Helmut and Kang, Rongjie and Guglielmino, Emanuele and Caldwell, Darwin G. and Pfeifer, Rolf},
	year = {2013},
	keywords = {PRC, softBodyRobotics},
}

@book{caluwaerts_design_2014,
	title = {Design and computational aspects of compliant tensegrity robots},
	abstract = {This dissertation explores the computational and hardware design aspects of compliant tensegrity robots and structures. I first focus on the control and computational features of robots based on the tensegrity design principle. Afterwards, I present the design of two hardware platforms developed to investigate the practical aspects of compliant tensegrity designs. In addition to this, I provide a general overview of the statics and dynamics of tensegrities.},
	author = {Caluwaerts, Ken},
	year = {2014},
}

@article{lukosevicius_reservoir_2009,
	title = {Reservoir computing approaches to recurrent neural network training},
	volume = {3},
	issn = {15740137},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013709000173},
	doi = {10.1016/j.cosrev.2009.03.005},
	abstract = {Echo State Networks and Liquid State Machines introduced a new paradigm in artificial
recurrent neural network (RNN) training, where an RNN (the reservoir) is generated
randomly and only a readout is trained. The paradigm, becoming known as reservoir computing, greatly facilitated the practical application of RNNs and outperformed classical fully trained RNNs in many tasks. It has lately become a vivid research field with numerous extensions of the basic idea, including reservoir adaptation, thus broadening the initial paradigm to using different methods for training the reservoir and the readout. This review systematically surveys both current ways of generating/adapting the reservoirs and training different types of readouts. It offers a natural conceptual classification of the techniques, which transcends boundaries of the current “brand-names” of reservoir methods, and thus aims to help in unifying the field and providing the reader with a detailed “map” of it.},
	language = {en},
	number = {3},
	urldate = {2021-07-19},
	journal = {Computer Science Review},
	author = {Lukoševičius, Mantas and Jaeger, Herbert},
	month = aug,
	year = {2009},
	pages = {127--149},
}

@article{tanaka_recent_2019,
	title = {Recent advances in physical reservoir computing: {A} review},
	volume = {115},
	issn = {08936080},
	shorttitle = {Recent advances in physical reservoir computing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608019300784},
	doi = {10.1016/j.neunet.2019.03.005},
	abstract = {Reservoir computing is a computational framework suited for temporal/sequential data processing. It is derived from several recurrent neural network models, including echo state networks and liquid state machines. A reservoir computing system consists of a reservoir for mapping inputs into a high-dimensional space and a readout for pattern analysis from the high-dimensional states in the reservoir. The reservoir is fixed and only the readout is trained with a simple method such as linear regression and classification. Thus, the major advantage of reservoir computing compared to other recurrent neural networks is fast learning, resulting in low training cost. Another advantage is that the reservoir without adaptive updating is amenable to hardware implementation using a variety of physical systems, substrates, and devices. In fact, such physical reservoir computing has attracted increasing attention in diverse fields of research. The purpose of this review is to provide an overview of recent advances in physical reservoir computing by classifying them according to the type of the reservoir. We discuss the current issues and perspectives related to physical reservoir computing, in order to further expand its practical applications and develop next-generation machine learning systems.},
	language = {en},
	urldate = {2021-07-19},
	journal = {Neural Networks},
	author = {Tanaka, Gouhei and Yamane, Toshiyuki and Héroux, Jean Benoit and Nakane, Ryosho and Kanazawa, Naoki and Takeda, Seiji and Numata, Hidetoshi and Nakano, Daiju and Hirose, Akira},
	month = jul,
	year = {2019},
	pages = {100--123},
}

@incollection{lopes_junior_nonlinear_2016,
	address = {Cham},
	title = {Nonlinear {Dynamics} and {Chaos}},
	isbn = {978-3-319-29981-5 978-3-319-29982-2},
	url = {http://link.springer.com/10.1007/978-3-319-29982-2_5},
	abstract = {This chapter presents an overview of nonlinear dynamics and chaos. It starts with a background revision of dynamical systems. Concepts of equilibrium points, linearization, stability, and Poincare´ maps are treated. Afterward, chaotic dynamics is explored. Horseshoe transformation is discussed in order to deﬁne the main aspects of chaos. Fractal characteristics are presented and discussed. Routes to chaos are investigated showing some deﬁnitions of bifurcation. Lyapunov exponents are deﬁned presenting a diagnostic tool for chaos. The main concepts and tools are then presented by considering a case study related to a shape memory alloy system. Single and two degrees of freedom systems are treated using a polynomial constitutive model to describe the restitution forces.},
	language = {en},
	urldate = {2021-07-19},
	booktitle = {Dynamics of {Smart} {Systems} and {Structures}},
	publisher = {Springer International Publishing},
	author = {Savi, Marcelo A.},
	editor = {Lopes Junior, Vicente and Steffen, Valder and Savi, Marcelo Amorim},
	year = {2016},
	doi = {10.1007/978-3-319-29982-2_5},
	pages = {93--117},
}
