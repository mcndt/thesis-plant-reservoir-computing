{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multirun experiment pipeline (HydroShoot)\n",
    "\n",
    "The following notebook establishes a generalized pipeline for evaluating a computing reservoir against a given task, given multiple experimental runs of the same reservoir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../'))  # for importing local packages from src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets\n",
    "\n",
    "Currently we aqree loading the HydroShoot dataset generated during the first semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/hydroshoot_large_trimmed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset properties:\n",
      "\tn_runs:      84\n",
      "\tn_steps:    168\n",
      "\tstate_size: 360\n",
      "\n",
      "Available targets: \n",
      "\tinput_Tac, input_u, input_hs, input_Rg, output_Rg, output_An, output_E, output_Tleaf\n",
      "\n",
      "Available state variables: \n",
      "\tstate_An, state_E, state_Eabs, state_Ei, state_Flux, state_FluxC, state_Tlc, state_gb, state_gs, state_psi_head, state_u\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.model.rc_dataset import ExperimentDataset\n",
    "\n",
    "dataset = ExperimentDataset(csv_path=DATASET_PATH)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining targets and observed state variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "\t- input_Tac\n",
      "\t- input_u\n",
      "\t- input_hs\n",
      "\t- input_Rg\n",
      "\t- output_Rg\n",
      "\t- output_An\n",
      "\t- output_E\n",
      "\t- output_Tleaf\n",
      "\n",
      "State variables:\n",
      "\t- state_An\n",
      "\t- state_E\n",
      "\t- state_Eabs\n",
      "\t- state_Ei\n",
      "\t- state_Flux\n",
      "\t- state_FluxC\n",
      "\t- state_Tlc\n",
      "\t- state_gb\n",
      "\t- state_gs\n",
      "\t- state_psi_head\n",
      "\t- state_u\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "from model_config import targets, state_variables\n",
    "\n",
    "print(f'Targets:')\n",
    "for target in targets:\n",
    "  print(f'\\t- {target}')\n",
    "\n",
    "print(f'\\nState variables:')\n",
    "for state_var in state_variables:\n",
    "  print(f'\\t- {state_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing, grouping and train-test splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Preprocessing performed: \n",
      "\n",
      "    1. The target signal for each run is computed.\n",
      "        - Target and reservoir are cast into a ndarray.\n",
      "    2. Target and reservoir signals are trimmed.\n",
      "        - A warmup mask is applied to target and reservoir.\n",
      "        - A night-time mask is applied to target and reservoir.\n",
      "    3. Target and reservoir are rescaled to zero-mean and unit variance\n",
      "        - Normalizing transform is fitted on the entire dataset of included experiment runs.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from hydroshoot_pipeline_utils import preprocess_data\n",
    "\n",
    "print(preprocess_data.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation state from the same calendar day of simulation inputs, \n",
      "    across all runs, are grouped together per day. Shape of X is assumed to be (runs, time_steps, nodes)\n",
      "\n",
      "    ```\n",
      "    GROUP 1 | GROUP 2 | GROUP 3 | GROUP 4 | ...\n",
      "    --------+---------+---------+---------+----\n",
      "    sim1/d1  sim1/d2   sim1/d3   /         /\n",
      "    /        sim2/d2   sim2/d3   sim2/d4   /       ...\n",
      "    /        /         sim3/d3   sim3/d4   sim3/d5 \n",
      "                                ...                ...\n",
      "    ```\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from hydroshoot_pipeline_utils import group_by_day\n",
    "\n",
    "print(group_by_day.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    - Train-test splitting is done at group scope (i.e. by calendar day)\n",
      "    - Training and testing ranges are chosen as contiguous blocks rather \n",
      "      than randomly selected.\n",
      "\n",
      "    e.g. for `interval_length = 8` and `test_ratio = 0.25`, \n",
      "    the consecutive groups are assigned as follows:\n",
      "\n",
      "    ```\n",
      "    g1     g2      g3      g4      g5      g6      g7     g8                   \n",
      "    ------+-------+-------+-------+-------+-------+------+------+\n",
      "    Train | Train | Train | Train | Train | Train | Test | Test | ... (repeat)\n",
      "    ```\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from hydroshoot_pipeline_utils import train_test_split_blocks\n",
    "\n",
    "print(train_test_split_blocks.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "- Readout model is a standard RidgeRegression model with intercept term and CV-tuned regularization strength $\\alpha$.\n",
    "- CV search grid is a progression of logarithmicly spaced values for regularization strength $\\alpha$.\n",
    "- CV and testing metric is NMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from src.learning.scorers import nmse_scorer\n",
    "\n",
    "# Define model\n",
    "readout = Pipeline([\n",
    "  ('ridge_regression', Ridge(alpha=1, fit_intercept=True))\n",
    "])\n",
    "\n",
    "# define search grid\n",
    "search_grid = [{\n",
    "  'ridge_regression__alpha': 10 ** np.linspace(np.log10(1e-4), np.log10(1e2), 50)\n",
    "}]\n",
    "\n",
    "# define cross-validation and testing metric\n",
    "scorer = nmse_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.learning.preprocessing import generate_mask\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.5  # 50% of samples are reserved for the test set.\n",
    "BLOCK_SIZE = 4  # Train test split in blocks of 4: 1111 0000 1111 0000 ...\n",
    "\n",
    "\n",
    "STATE_SIZE = 32                         # Sixteen random nodes are selected as reservoir readouts\n",
    "RUN_IDS = np.arange(dataset.n_runs())   # All runs are used\n",
    "\n",
    "\n",
    "WARMUP_STEPS = 4 * 24                   # First 4 days of each simulation are discarded\n",
    "DAY_MASK = generate_mask(5, 21)         # All nighttime data between 5am and 9pm (inclusive) is discarded\n",
    "\n",
    "\n",
    "STRATEGIES = [\n",
    "  {\n",
    "    'strat_name': '3_folds',\n",
    "    'fold_generator': lambda groups : GroupKFold(n_splits=3)\n",
    "  },\n",
    "  {\n",
    "    'strat_name': '4_folds',\n",
    "    'fold_generator': lambda groups : GroupKFold(n_splits=4)\n",
    "  },\n",
    "  {\n",
    "    'strat_name': '5_folds',\n",
    "    'fold_generator': lambda groups : GroupKFold(n_splits=5)\n",
    "  },\n",
    "  {\n",
    "    'strat_name': 'LeaveOneOut',\n",
    "    'fold_generator': lambda groups : GroupKFold(n_splits=np.unique(groups).shape[0])\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a manifest of model combinations to be fitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydroshoot_pipeline_utils import direct_target_generator\n",
    "from model_config import input_targets as input_target_names, output_targets as output_target_Names\n",
    "\n",
    "input_target_names = dataset.get_input_variables()\n",
    "input_targets_runs = [list(direct_target_generator(dataset, name, RUN_IDS)) for name in input_target_names]\n",
    "input_targets = list(zip(input_target_names, input_targets_runs))\n",
    "\n",
    "\n",
    "output_target_names = dataset.get_output_variables()\n",
    "output_target_runs = [list(direct_target_generator(dataset, name, RUN_IDS)) for name in output_target_names]\n",
    "output_targets = list(zip(output_target_names, output_target_runs))\n",
    "\n",
    "TARGETS = all_targets = [*input_targets, *output_targets]\n",
    "STATE_VARS = state_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 352 fits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 89/352 [00:14<00:41,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scores to scores_3_folds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 176/352 [00:28<00:29,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scores to scores_4_folds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 264/352 [00:45<00:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scores to scores_5_folds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [02:06<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scores to scores_LeaveOneOut.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from src.learning.training import perform_gridsearch\n",
    "from hydroshoot_pipeline_utils import direct_reservoir_generator\n",
    "\n",
    "\n",
    "total_loops = len(STRATEGIES) * len(TARGETS) * len(STATE_VARS)\n",
    "print(f'Performing {total_loops} fits...')\n",
    "\n",
    "\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "\n",
    "with tqdm(total=total_loops) as pbar:\n",
    "  for strategy in STRATEGIES:\n",
    "    for state_var in STATE_VARS:\n",
    "      # the reservoir is the same for every target\n",
    "      reservoir_run_list = list(direct_reservoir_generator(dataset, state_var, RUN_IDS, STATE_SIZE, random_state=42))\n",
    "      \n",
    "      for target_name, target_generator in TARGETS:\n",
    "        # Preprocess data for model fit\n",
    "        X, y = preprocess_data(dataset, RUN_IDS, target_generator, reservoir_run_list, STATE_SIZE,\n",
    "                               warmup_steps=WARMUP_STEPS, day_mask=DAY_MASK)\n",
    "        \n",
    "        # Generate group labels and make train/test split\n",
    "        days_per_run = X.shape[1] // DAY_MASK.sum()\n",
    "        groups = group_by_day(X, days_per_run)\n",
    "        train, test = train_test_split_blocks(X, y, groups, TRAIN_TEST_RATIO, BLOCK_SIZE * 2)\n",
    "        X_train, y_train, groups_train = train\n",
    "\n",
    "        # fit model\n",
    "        folds = strategy['fold_generator'](groups_train)\n",
    "        model, scores = perform_gridsearch(readout, X_train, y_train, groups_train, folds, search_grid, verbose=False)\n",
    "        (train_mean, train_std), (cv_mean, cv_std) = scores\n",
    "\n",
    "        # determine test score\n",
    "        X_test, y_test, _ = test\n",
    "        test_score = scorer(model, X_test, y_test)\n",
    "        models[(target_name, state_var)] = model\n",
    "        results.append({\n",
    "            'target': target_name,\n",
    "            'state_var': state_var,\n",
    "            'test_score': test_score,\n",
    "            'train_mean': train_mean,\n",
    "            'train_std': train_std,\n",
    "            'cv_mean': cv_mean,\n",
    "            'cv_std': cv_std,\n",
    "            'strategy': strategy['strat_name'],\n",
    "            'dataset': 'HydroShoot_large'\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    filename = f'scores_{strategy[\"strat_name\"]}.csv'\n",
    "    results_df.to_csv(filename)\n",
    "    print(f'Saved scores to {filename}')\n",
    "    models = {}\n",
    "    results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4121734fd62df77af0346899b5494e4291ab6203437ffd47de4eeaba662aa73c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('rc-plants')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
