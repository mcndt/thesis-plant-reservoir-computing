{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))  # for importing local packages from src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'NEW_STORAGE/test_large.csv'\n",
    "dataset_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run_id', 'time', 'type', 'input_Tac', 'input_u', 'input_hs',\n",
       "       'input_Rg', 'output_Rg', 'output_An', 'output_E', 'output_Tleaf',\n",
       "       'state_id', 'state_type', 'state_Ci', 'state_gb', 'state_Ei',\n",
       "       'state_FluxC', 'state_Tlc', 'state_An', 'state_Flux', 'state_psi_head',\n",
       "       'state_u', 'state_E', 'state_Eabs', 'state_gs', 'state_par_photo.dHd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14112, 7)\n",
      "(14112, 7)\n",
      "(5080320, 18)\n",
      "\n",
      "Inputs: ('input_Tac', 'input_u', 'input_hs', 'input_Rg')\n",
      "Outputs: ('output_Rg', 'output_An', 'output_E', 'output_Tleaf')\n",
      "Targets: ('input_Tac', 'input_u', 'input_hs', 'input_Rg', 'output_Rg', 'output_An', 'output_E', 'output_Tleaf')\n",
      "State: ('state_Ci', 'state_gb', 'state_Ei', 'state_FluxC', 'state_Tlc', 'state_An', 'state_Flux', 'state_psi_head', 'state_u', 'state_E', 'state_Eabs', 'state_gs', 'state_par_photo.dHd')\n",
      "n_runs: 84\n",
      "n_steps: 168\n",
      "state_size: 360\n",
      "\n",
      "Input target: (168,)\n",
      "Output target: (168,)\n",
      "Reservoir state: (168, 360)\n"
     ]
    }
   ],
   "source": [
    "class ExperimentDataset:\n",
    "    \"\"\"Wrapper class for handling a dataset from a single RC experiment run.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_df=None, csv_path=None):\n",
    "        \"\"\"Load a experiment dataset from csv file.\"\"\"\n",
    "        self._inputs: pd.DataFrame = None\n",
    "        self._outputs: pd.DataFrame = None\n",
    "        self._state: pd.DataFrame = None\n",
    "\n",
    "        if dataset_df is not None:\n",
    "          self.load_data(dataset_df)\n",
    "        elif csv_path is not None:\n",
    "          self.load_dataframe(csv_path)\n",
    "        else:\n",
    "          raise Exception('Must set kwarg \"dataset_df\" or \"csv_path\"')\n",
    "\n",
    "    def load_dataframe(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        this.load_data(df)\n",
    "\n",
    "    def load_data(self, dataset_df):\n",
    "        self._inputs = dataset_df[dataset_df[\"type\"] == \"INPUT\"].dropna(\n",
    "            how=\"all\", axis=1\n",
    "        )\n",
    "        self._outputs = dataset_df[dataset_df[\"type\"] == \"OUTPUT\"].dropna(\n",
    "            how=\"all\", axis=1\n",
    "        )\n",
    "        self._state = dataset_df[dataset_df[\"type\"] == \"STATE\"].dropna(\n",
    "            how=\"all\", axis=1\n",
    "        )\n",
    "        self._state[\"state_id\"] = self._state[\"state_id\"].astype(int)\n",
    "        assert len(self._inputs) == len(\n",
    "            self._outputs\n",
    "        ), \"Input and output set have different lengths.\"\n",
    "\n",
    "    def get_input_variables(self) -> tuple:\n",
    "        \"\"\"Get the input keys available.\"\"\"\n",
    "        input_col_names = self._inputs.columns\n",
    "        return tuple(filter(lambda x: x.startswith(\"input_\"), input_col_names))\n",
    "\n",
    "    def get_output_variables(self) -> tuple:\n",
    "        \"\"\"Get the input output available.\"\"\"\n",
    "        output_col_names = self._outputs.columns\n",
    "        return tuple(filter(lambda x: x.startswith(\"output_\"), output_col_names))\n",
    "\n",
    "    def get_targets(self) -> tuple:\n",
    "        \"\"\"Get the target keys available.\"\"\"\n",
    "        return (*self.get_input_variables(), *self.get_output_variables())\n",
    "\n",
    "    def get_state_variables(self) -> tuple:\n",
    "        \"\"\"Get the state variables available.\"\"\"\n",
    "        state_col_names = self._state.loc[\n",
    "            :, ~self._state.columns.isin([\"state_id\", \"state_type\"])\n",
    "        ].columns\n",
    "        return tuple(filter(lambda x: x.startswith(\"state_\"), state_col_names))\n",
    "\n",
    "    def n_runs(self) -> int:\n",
    "        return len(self._inputs.groupby('run_id'))\n",
    "\n",
    "    def n_steps(self) -> int:\n",
    "        return self._inputs.groupby('run_id').size()[0]\n",
    "\n",
    "    def state_size(self) -> int:\n",
    "        return len(self._state.groupby(\"state_id\"))\n",
    "\n",
    "    def get_target(self, target_key, run_id) -> pd.Series:\n",
    "        \"Get a target signal as pandas Series by the target key.\"\n",
    "        assert (\n",
    "            target_key in self.get_targets()\n",
    "        ), f\"{target_key} not in available targets.\"\n",
    "        source = self._inputs if target_key.startswith(\"input_\") else self._outputs\n",
    "        source = source.groupby('run_id').get_group(run_id)\n",
    "        target_series = source[target_key]\n",
    "        target_series.index = source[\"time\"]\n",
    "        return target_series\n",
    "\n",
    "    def get_state(self, state_key, run_id) -> pd.DataFrame:\n",
    "        \"Get the entire reservoir state of variable as pandas DataFrame by the state key.\"\n",
    "        assert (\n",
    "            state_key in self.get_state_variables()\n",
    "        ), f\"{state_key} not in available state variables.\"\n",
    "\n",
    "        source = self._state.groupby('run_id').get_group(run_id)\n",
    "        return source.pivot(index=\"time\", columns=[\"state_id\"], values=state_key)\n",
    "\n",
    "\n",
    "dataset = ExperimentDataset(dataset_df=dataset_df)  \n",
    "print(dataset._inputs.shape)\n",
    "print(dataset._outputs.shape)\n",
    "print(dataset._state.shape)\n",
    "print()\n",
    "print(f'Inputs: {dataset.get_input_variables()}')\n",
    "print(f'Outputs: {dataset.get_output_variables()}')\n",
    "print(f'Targets: {dataset.get_targets()}')\n",
    "print(f'State: {dataset.get_state_variables()}')\n",
    "print(f'n_runs: {dataset.n_runs()}')\n",
    "print(f'n_steps: {dataset.n_steps()}')\n",
    "print(f'state_size: {dataset.state_size()}')\n",
    "print()\n",
    "print('Input target:', dataset.get_target('input_Tac', 0).shape)\n",
    "print('Output target:', dataset.get_target('output_An', 0).shape)\n",
    "print('Reservoir state:', dataset.get_state('state_E', 0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9f3c9d4e0cae94601994f394c7f1bebe9832a9f191b783a132536a9bc27a9aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('hydroshoot': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
